{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzONFe0W2mHw"
   },
   "source": [
    "# Especialização em Ciência de Dados - PUC-Rio\n",
    "# Machine Learning\n",
    "## Exercício 2: Problemas de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnHlnwLF3jh5"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "__Alunos:__ <br>\n",
    "        Cícero Felipe Ricci Bressane <br>\n",
    "        José Douglas Nascimento <br>\n",
    "        Ronaldo Costa <br>\n",
    "        Victor Mouffron Carvalho Machado\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oa1y_RrG3C7T"
   },
   "source": [
    "### Escolha um dataset simples para problemas de classificação diferente do usado em aula (preferencialmente do UCI Machine Learning Repository - https://archive.ics.uci.edu/ml/index.php) e treine os modelos de classificação  aprendidos em aula (Árvore de Classificação, KNN, Naive Bayes, SVM e Regressão Logística. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbjlQ2WB3EkA"
   },
   "source": [
    "O dataset escolhido foi obtido no Kaggle no link: https://www.kaggle.com/c/titanic. Trata-se de um dataset com informações de passageiros do navio titanic em que cada linha representa um pasageiro e possui rótulo indicando se a pessoa sobriveveu ou não ao acidente.\n",
    "\n",
    "\n",
    "__Vamos aplicar os modelos!__\n",
    "\n",
    "\n",
    "![Titanic](img/titanic.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover as variáveis __PassengerId__,__Name__,__Ticket__ e __Cabin__, pois nãos as utilizaremos na predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "variables_to_drop = ['PassengerId','Name','Ticket','Cabin']\n",
    "df.drop(variables_to_drop,axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O campo \"Age\" possui dados faltantes, vamos preencher com a mediana e com o valor mais comum, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos utilizar one hot encoding para transformar variáveis categóricas em numéricas. Também vamos separar o dataset entre treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 0\n",
    "df = pd.get_dummies(df)\n",
    "X = df.iloc[:,1:].values\n",
    "y = df.iloc[:,0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo  Regressão logística  foi de  0.7982062780269058\n",
      "A acurácia do modelo  Árvore de classificação  foi de  0.7847533632286996\n",
      "A acurácia do modelo  KNN  foi de  0.7443946188340808\n",
      "A acurácia do modelo  Naive bayes  foi de  0.7892376681614349\n",
      "A acurácia do modelo  SVM  foi de  0.7533632286995515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = [\n",
    "            ('Regressão logística',LogisticRegression(random_state=random_seed)),\n",
    "            ('Árvore de classificação',DecisionTreeClassifier(random_state=random_seed)),\n",
    "            ('KNN',KNeighborsClassifier()),\n",
    "            ('Naive bayes',GaussianNB()),\n",
    "            ('SVM',SVC(random_state=random_seed)),    \n",
    "          ]\n",
    "\n",
    "for name,model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_pred,y_test) \n",
    "    print('A acurácia do modelo ',name,' foi de ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umP9jBPk3Euz"
   },
   "source": [
    "**Agora pesquise outras bibliotecas, modelos de classificação ou funcionalidades (não estudados em sala) e aplique-os no problema. Lembre-se que quanto mais você pesquisar e treinar, mais irá aprender.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTdps4lW3R8n"
   },
   "source": [
    "Além desses modelos temos os ensembles, vistos na Aula 5. Uma biblioteca que tem tido muito sucesso em competições de ML é a xgboost que implementa um ensemble. Para mais informações ver o paper Chen & Guestrin (2016) que descreve esse algoritmo, disponível em https://arxiv.org/pdf/1603.02754.pdf - XGBoost: A Scalable Tree Boosting System. <br>\n",
    "Além disso, há outros modelos no scikit-learn como Stochastic Gradient Descent.\n",
    "__OBS: para rodar o código abaixo é necessário ter a biblioteca xgboost instalada__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo  XGBoost  foi de  0.8475336322869955\n",
      "A acurácia do modelo  Random forest  foi de  0.8295964125560538\n",
      "A acurácia do modelo  Gradient Boosting  foi de  0.8475336322869955\n",
      "A acurácia do modelo  Ada Boosting  foi de  0.7982062780269058\n",
      "A acurácia do modelo  Stochastic Gradient Descent  foi de  0.6233183856502242\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "models = [\n",
    "            ('XGBoost',xgb.XGBClassifier(random_state=random_seed)),\n",
    "            ('Random forest',RandomForestClassifier(random_state=random_seed)),\n",
    "            ('Gradient Boosting',GradientBoostingClassifier(random_state=random_seed)),\n",
    "            ('Ada Boosting',AdaBoostClassifier(random_state=random_seed)),\n",
    "            ('Stochastic Gradient Descent',SGDClassifier(random_state=random_seed))\n",
    "          ]\n",
    "\n",
    "for name,model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_pred,y_test) \n",
    "    print('A acurácia do modelo ',name,' foi de ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11l-FXsq3SEc"
   },
   "source": [
    "**O que você aprendeu sobre o problema de classificação deste dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SaICNZX43cNy"
   },
   "source": [
    "Aprendi que nem sempre os modelos mais complexos  trazem os melhores resultados. Nesse caso, um modelo simples como uma regressão logística teve um desempenho superior ao modelo SVM, por isso devemos sempre testar diferentes modelos para o dataset específico que estamos trabalhando. Além disso, a combinação de modelos através de ensembles pode ser muito poderosa para melhor a predição para um problema de ML."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML - Exercício 2 - Problemas de Classificação.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
