{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - 4. Regressão.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U09YgBYug4J",
        "colab_type": "text"
      },
      "source": [
        "# Especialização em Ciência de Dados - PUC-Rio\n",
        "# Machine Learning\n",
        "## Problemas de Regressão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jj3_aqYuzDK",
        "colab_type": "text"
      },
      "source": [
        "# Importação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsS3uX9tyMDp",
        "colab_type": "text"
      },
      "source": [
        "http://lib.stat.cmu.edu/datasets/boston\n",
        "\n",
        "Para este projeto, investigaremos o dataset Boston House Price, um dataset para problemas de regressão em que todos os atributos são numéricos.\n",
        "\n",
        "Cada registro no banco de dados descreve um subúrbio ou cidade de Boston. Os dados foram retirados da Área Estatística Metropolitana Padrão de Boston (SMSA) em 1970. Os atributos são definidos da seguinte forma (retirado do UCI Machine Learning Repository):\n",
        "\n",
        "1. CRIM: Taxa de criminalidade per capita por cidade\n",
        "2. ZN: Proporção de terrenos residenciais divididos em lotes com mais de 25.000 pés quadrados\n",
        "3. INDUS: Proporção de acres não comerciais por cidade\n",
        "4. CHAS: Variável fictícia CHAS Charles River (= 1 se o trecho limita o rio; 0 caso contrário)\n",
        "5. NOX: Concentração de óxidos nítricos (partes por 10 milhões)\n",
        "6. RM: número médio de quartos por habitação\n",
        "7. AGE: proporção de unidades ocupadas construídas antes de 1940\n",
        "8. DIS: Distâncias ponderadas para cinco centros de emprego em Boston\n",
        "9. RAD: Índice de acessibilidade às rodovias radiais\n",
        "10. TAX: Taxa de imposto sobre o valor total da propriedade por 10 mil dólares\n",
        "11. PTRATIO: Proporção de alunos por professor por cidade\n",
        "12. B: 1000(Bk - 0.63)^2 onde Bk é a proporção de negros por cidade\n",
        "13. LSTAT: % do menor status da população\n",
        "14. MEDV: Valor médio das casas ocupadas pelos proprietários em mil dólares\n",
        "\n",
        "Podemos ver que os atributos de entrada têm uma mistura de unidades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WWAIhpcygDh",
        "colab_type": "code",
        "outputId": "dfe01fa5-5fde-4fb2-b3c5-f179c13783f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Datasets do scikit-learn: https://scikit-learn.org/stable/datasets/index.html\n",
        "\n",
        "# Importação de pacotes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "# Carrega o dataset boston\n",
        "boston = datasets.load_boston()\n",
        "\n",
        "# Extraindo X, Y e os nomes das colunas dos atributos\n",
        "X = boston[\"data\"]\n",
        "Y = boston[\"target\"]\n",
        "names = boston[\"feature_names\"]\n",
        "\n",
        "# Se precisar converter para dataframe\n",
        "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuhKsCG4WaN",
        "colab_type": "text"
      },
      "source": [
        "# Modelos de Regressão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PtJr6zcySLA",
        "colab_type": "text"
      },
      "source": [
        "Para avaliar cada algoritmo, iremos usar diversas métricas, dentre elas, a medida de erro quadrático médio (MSE). Na implementação do scikit-learn, os valores médios dos erros quadráticos estão invertidos (negativos), devido a uma peculiaridade da função usada (para mais detalhes, consulte a documentação).\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifhMJHSqEQMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dos pacotes\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### Treinamento e avaliação do modelo\n",
        "def treinarAvaliarModeloRegressao (modelo):\n",
        "  \n",
        "    # Seed ou semente: pode ser qualquer número, e garante que os resultados possam ser reproduzidos de forma idêntica toda vez que o script for rodado. \n",
        "    # Isto é muito importante quando trabalhamos com modelos ou métodos que utilizam de algum tipo de aleatoriedade.\n",
        "    seed = 7\n",
        "    \n",
        "    ## 1. Usando validação cruzada\n",
        "\n",
        "    print(\"=== Usando validação cruzada ===\")\n",
        "\n",
        "    # Definição do número de folds \n",
        "    num_folds = 10\n",
        "    \n",
        "    # Definindo os folds\n",
        "    kfold = KFold(num_folds, True, random_state = seed)\n",
        "\n",
        "    # Aplicação do modelo e cálculo dos resultados\n",
        "    resultado = cross_validate(modelo, X, Y, cv = kfold,\n",
        "                            scoring=('neg_mean_squared_error', 'r2'), # neg_mean_squared_error virá com valor negativo!\n",
        "                            return_train_score=True)\n",
        "\n",
        "    print(\"RMSE de treino: \", np.sqrt(abs(resultado['train_neg_mean_squared_error'].mean())) )\n",
        "    print(\"RMSE de teste: \", np.sqrt(abs(resultado['test_neg_mean_squared_error'].mean())) )\n",
        "    print(\"MSE de treino: \", resultado['train_neg_mean_squared_error'].mean() )\n",
        "    print(\"MSE de teste: \", resultado['test_neg_mean_squared_error'].mean() )\n",
        "    print(\"R2 de treino: \", resultado['train_r2'].mean() )\n",
        "    print(\"R2 de teste: \", resultado['test_r2'].mean() )\n",
        "    print(\"\\n\")\n",
        "\n",
        "    ## 2. Usando conjuntos de treino e teste em vez de validação cruzada\n",
        "    \n",
        "    print(\"=== Usando particionamento treino-teste ===\")\n",
        "    \n",
        "    # Definição do tamanho do conjunto de teste para 33%\n",
        "    teste_size = 0.33\n",
        "\n",
        "    # Criando os conjuntos de dados de treino e de teste\n",
        "    X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)\n",
        "\n",
        "    # Treinamento\n",
        "    modeloTreinado = modelo.fit(X_treino, Y_treino)\n",
        "\n",
        "    # Previsões\n",
        "    Y_pred = modeloTreinado.predict(X_teste)\n",
        "\n",
        "    # Resultados\n",
        "    corretas = (Y_teste == Y_pred).sum()\n",
        "    total = Y_teste.shape[0]\n",
        "    \n",
        "    # Print dos resultados \n",
        "    print(\"RMSE de teste: \", np.sqrt(metrics.mean_squared_error(Y_teste, Y_pred)))\n",
        "    print(\"MSE de teste: \", metrics.mean_squared_error(Y_teste, Y_pred))\n",
        "    print(\"R2 de teste: \", metrics.r2_score(Y_teste, Y_pred))\n",
        "    \n",
        "    return;\n",
        "\n",
        "  \n",
        "### Impressão dos coeficientes (para regressão linear)\n",
        "def imprimirCoeficientes (modelo):\n",
        "    # Impressão dos coeficientes (intercept e slope)\n",
        "    print(\"Beta0: \", modelo.intercept_)\n",
        "    print(\"\\n\")\n",
        "    coeff_df = pd.DataFrame(modelo.coef_, names, columns=['Coeficientes'])  \n",
        "    print(coeff_df)\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kgJTUGx1CpZ",
        "colab_type": "text"
      },
      "source": [
        "## Regressão Linear\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        "A regressão linear pressupõe que as variáveis de entrada tenham uma distribuição gaussiana. Também é assumido que as variáveis de entrada são relevantes para a variável de saída e que não são altamente correlacionadas entre si. Podemos construir um modelo de regressão linear usando a classe LinearRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K1wpOo70oMT",
        "colab_type": "code",
        "outputId": "eae58ba9-3f99-421e-ef5d-cf4ebb4c986b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# Import da função\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Escolhendo o modelo\n",
        "modelo = LinearRegression()\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)\n",
        "print(\"\\n\")\n",
        "imprimirCoeficientes(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  4.66883016698375\n",
            "RMSE de teste:  4.873038252601078\n",
            "MSE de treino:  -21.797975128137516\n",
            "MSE de teste:  -23.746501811313365\n",
            "R2 de treino:  0.7417692439965816\n",
            "R2 de teste:  0.7181683241114103\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  5.032127524575092\n",
            "MSE de teste:  25.32230742358624\n",
            "R2 de teste:  0.6663089606572568\n",
            "\n",
            "\n",
            "Beta0:  24.6495548658218\n",
            "\n",
            "\n",
            "         Coeficientes\n",
            "CRIM        -0.109873\n",
            "ZN           0.025843\n",
            "INDUS        0.009282\n",
            "CHAS         2.590511\n",
            "NOX        -15.639798\n",
            "RM           5.350326\n",
            "AGE         -0.014098\n",
            "DIS         -1.307287\n",
            "RAD          0.269510\n",
            "TAX         -0.011260\n",
            "PTRATIO     -0.968767\n",
            "B            0.010029\n",
            "LSTAT       -0.386575\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pZ-ZBe10lOV",
        "colab_type": "text"
      },
      "source": [
        "Isto significa que para o aumento de uma unidade em NOX há uma diminuição de 15.63 no target, e que para a diminuição de uma unidade em CHAS, há um aumento em 2.59 no target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475Yp60C1Q7-",
        "colab_type": "text"
      },
      "source": [
        "## Regressão Ridge\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
        "\n",
        "A regressão Ridge é uma extensão da regressão linear em que a função de perda é modificada para minimizar a complexidade do modelo medido como a soma do valor ao quadrado dos valores do coeficiente (também chamado de norma L2). Podemos construir um modelo de regressão Ridge usando a classe Ridge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdSp0kfS1RAh",
        "colab_type": "code",
        "outputId": "a92d2f80-7526-477a-c5db-a34c41756dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "modelo = Ridge()\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)\n",
        "print(\"\\n\")\n",
        "imprimirCoeficientes(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  4.687047665576289\n",
            "RMSE de teste:  4.88772853021252\n",
            "MSE de treino:  -21.96841581938414\n",
            "MSE de teste:  -23.88989018505344\n",
            "R2 de treino:  0.7397462418961597\n",
            "R2 de teste:  0.716092748999703\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  5.079243301210836\n",
            "MSE de teste:  25.79871251289515\n",
            "R2 de teste:  0.6600310134409777\n",
            "\n",
            "\n",
            "Beta0:  18.809734112178386\n",
            "\n",
            "\n",
            "         Coeficientes\n",
            "CRIM        -0.109709\n",
            "ZN           0.027939\n",
            "INDUS       -0.021965\n",
            "CHAS         2.525037\n",
            "NOX         -7.845890\n",
            "RM           5.423987\n",
            "AGE         -0.019643\n",
            "DIS         -1.184205\n",
            "RAD          0.253371\n",
            "TAX         -0.012005\n",
            "PTRATIO     -0.869945\n",
            "B            0.010187\n",
            "LSTAT       -0.395127\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPeH7R285ESu",
        "colab_type": "text"
      },
      "source": [
        "## Regressão LASSO\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
        "\n",
        "A regressão LASSO (Least Absolute Shrinkage and Selection Operator) é uma modificação da regressão linear em que a função de perda é modificada para minimizar a complexidade do modelo medido como a soma do valor absoluto dos valores de coeficiente (também chamado a norma L1). Podemos construir um modelo LASSO usando a classe Lasso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc4m-zDP5EYp",
        "colab_type": "code",
        "outputId": "d1900477-3706-4e2a-f88c-8865ee7aa4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "modelo = Lasso()\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)\n",
        "print(\"\\n\")\n",
        "imprimirCoeficientes(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  5.168851691637753\n",
            "RMSE de teste:  5.361519381280976\n",
            "MSE de treino:  -26.717027810146465\n",
            "MSE de teste:  -28.74589007585154\n",
            "R2 de treino:  0.6833717306814954\n",
            "R2 de teste:  0.6620846823996761\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  4.898615578574049\n",
            "MSE de teste:  23.99643458664836\n",
            "R2 de teste:  0.6837809815751457\n",
            "\n",
            "\n",
            "Beta0:  30.662179808858333\n",
            "\n",
            "\n",
            "         Coeficientes\n",
            "CRIM        -0.032079\n",
            "ZN           0.033424\n",
            "INDUS       -0.000000\n",
            "CHAS         0.000000\n",
            "NOX         -0.000000\n",
            "RM           2.314710\n",
            "AGE          0.023226\n",
            "DIS         -0.428535\n",
            "RAD          0.244641\n",
            "TAX         -0.015521\n",
            "PTRATIO     -0.697395\n",
            "B            0.007468\n",
            "LSTAT       -0.671867\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_pbyuJp1lrh",
        "colab_type": "text"
      },
      "source": [
        "## Regressão ElasticNet\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
        "\n",
        "O ElasticNet é um método de regularização de regressão que combina as propriedades da regressão de Ridge e da regressão LASSO. Ele procura minimizar a complexidade do modelo de regressão (magnitude e número de coeficientes de regressão) penalizando o modelo usando a norma L2 (soma dos valores do coeficiente ao quadrado) e a norma L1 (soma dos valores absolutos do coeficiente). Podemos construir um modelo ElasticNet usando a classe ElasticNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9I3ZctE1lwH",
        "colab_type": "code",
        "outputId": "5a8813af-f23b-486e-c14d-6288a6c14fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "modelo = ElasticNet()\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)\n",
        "print(\"\\n\")\n",
        "imprimirCoeficientes(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  5.139987442511225\n",
            "RMSE de teste:  5.282842072240193\n",
            "MSE de treino:  -26.419470909173082\n",
            "MSE de teste:  -27.908420360231055\n",
            "R2 de treino:  0.6869761153286654\n",
            "R2 de teste:  0.6707573051925824\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  4.8045884826654515\n",
            "MSE de teste:  23.0840704877615\n",
            "R2 de teste:  0.6958038876762297\n",
            "\n",
            "\n",
            "Beta0:  39.173320396182206\n",
            "\n",
            "\n",
            "         Coeficientes\n",
            "CRIM        -0.061006\n",
            "ZN           0.044829\n",
            "INDUS       -0.021688\n",
            "CHAS         0.000000\n",
            "NOX         -0.000000\n",
            "RM           1.389340\n",
            "AGE          0.028021\n",
            "DIS         -0.596196\n",
            "RAD          0.308559\n",
            "TAX         -0.017516\n",
            "PTRATIO     -0.751238\n",
            "B            0.006934\n",
            "LSTAT       -0.733593\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WnWuh1g11fi",
        "colab_type": "text"
      },
      "source": [
        "## K-Nearest Neighbors\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
        "\n",
        "O KNN localiza as k instâncias mais semelhantes no\n",
        "conjunto de dados de treinamento para uma nova instância de dados. Dos k vizinhos, a variável de saída média ou mediana é tomada como a previsão. É importante notar a métrica da distância usada (o argumento da métrica). A distância de Minkowski é usada por padrão, que é uma generalização da distância euclidiana (usada quando todas as entradas têm a mesma escala) e da distância de Manhattan (usada quando as escalas das variáveis de entrada diferem). Podemos  construir um modelo KNN para regressão usando a classe KNeighborsRegressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyFl-5A811kp",
        "colab_type": "code",
        "outputId": "d183efc4-f006-44a8-8638-35b62fd1d43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "modelo = KNeighborsRegressor()\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                    weights='uniform')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  4.948155477065862\n",
            "RMSE de teste:  6.233162942412678\n",
            "MSE de treino:  -24.484242625216886\n",
            "MSE de teste:  -38.852320266666666\n",
            "R2 de treino:  0.7097378290240509\n",
            "R2 de teste:  0.5094444355002923\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  5.872843214759755\n",
            "MSE de teste:  34.490287425149695\n",
            "R2 de teste:  0.5454956112171632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVzuOOkG2E_E",
        "colab_type": "text"
      },
      "source": [
        "## Árvores de Decisão\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "As árvores de decisão ou as Árvores de Classificação e Regressão (CART, como são conhecidas) usam os dados de treinamento para selecionar os melhores pontos para dividir os dados, a fim de minimizar uma métrica de custo. A métrica de custo padrão para árvores de decisão de regressão é o erro médio quadrático, especificado no parâmetro critério. Podemos criar um modelo CART para regressão usando a classe DecisionTreeRegressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmJeWBvc2FEL",
        "colab_type": "code",
        "outputId": "7abc6833-09d4-4789-ad26-79633d88e95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "modelo = DecisionTreeRegressor()\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
            "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      presort=False, random_state=None, splitter='best')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  0.0\n",
            "RMSE de teste:  4.830216615123964\n",
            "MSE de treino:  0.0\n",
            "MSE de teste:  -23.33099254901961\n",
            "R2 de treino:  1.0\n",
            "R2 de teste:  0.7015464705789144\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  4.693791287084098\n",
            "MSE de teste:  22.03167664670659\n",
            "R2 de teste:  0.709672070727053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNp7h-xY2vU8",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machines\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
        "\n",
        "O modelo SVM foi desenvolvido inicialmente para classificação binária e depois estendido para os problemas de predição de valor real e denominado Support Vector Regression (SVR). Podemos criar um modelo SVM para regressão usando a classe SVR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zb2TcvJ2vaw",
        "colab_type": "code",
        "outputId": "b8e88e59-ea61-467c-cda8-3b24f3fd30c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "modelo = SVR(gamma='auto')\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModeloRegressao(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
            "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "RMSE de treino:  8.47863932064203\n",
            "RMSE de teste:  9.150558886796565\n",
            "MSE de treino:  -71.88732472953714\n",
            "MSE de teste:  -83.73272794073159\n",
            "R2 de treino:  0.14847067230564637\n",
            "R2 de teste:  0.0019497717923192214\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "RMSE de teste:  8.71880830440189\n",
            "MSE de teste:  76.01761824890737\n",
            "R2 de teste:  -0.0017411769596671345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_WaUApV4dvi",
        "colab_type": "text"
      },
      "source": [
        "# Comparação de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8XK8ymtrV_l",
        "colab_type": "text"
      },
      "source": [
        "Vamos criar uma função para comparar diversos modelos de regressão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRxpInnF4mgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        " \n",
        "# Lista de modelos a avaliar\n",
        "models = []\n",
        "models.append(('LinearRegression', LinearRegression()))\n",
        "models.append(('Ridge', Ridge()))\n",
        "models.append(('Lasso', Lasso()))\n",
        "models.append(('ElasticNet', ElasticNet()))\n",
        "models.append(('KNN', KNeighborsRegressor()))\n",
        "models.append(('CART', DecisionTreeRegressor()))\n",
        "models.append(('SVM', SVR(gamma=\"auto\")))\n",
        "\n",
        "def comparaModelos(X, Y, models):\n",
        "  \n",
        "  # Treinamento e avaliação de cada modelo\n",
        "  results = []\n",
        "  names = []  \n",
        "  scoring = 'neg_mean_squared_error' # Virá com valor negativo!\n",
        "  for name, model in models:\n",
        "    kfold = KFold(n_splits=10, random_state=7)\n",
        "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    # imprime MSE, desvio padrão do MSE e RMSE\n",
        "    msg = \"%s: MSE %0.2f (%0.2f) - RMSE %0.2f\" % (name, cv_results.mean(), cv_results.std(), np.sqrt(abs(cv_results.mean())))\n",
        "    print(msg)\n",
        "\n",
        "  # Comparação dos algoritmos em boxplot\n",
        "  fig = pyplot.figure()\n",
        "  fig.suptitle('Comparação dos Algoritmos')\n",
        "  ax = fig.add_subplot(111)\n",
        "  pyplot.boxplot(results)\n",
        "  ax.set_xticklabels(names)\n",
        "  pyplot.show()\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peGBt5dPrRRX",
        "colab_type": "text"
      },
      "source": [
        "Aplicando a função..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxgVsoswqOfM",
        "colab_type": "code",
        "outputId": "d7ea6625-c8d7-499a-de93-810c0c229c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "comparaModelos(X, Y, models)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression: MSE -34.71 (45.57) - RMSE 5.89\n",
            "Ridge: MSE -34.08 (45.90) - RMSE 5.84\n",
            "Lasso: MSE -34.46 (27.89) - RMSE 5.87\n",
            "ElasticNet: MSE -31.16 (22.71) - RMSE 5.58\n",
            "KNN: MSE -107.29 (79.84) - RMSE 10.36\n",
            "CART: MSE -41.62 (31.48) - RMSE 6.45\n",
            "SVM: MSE -91.05 (71.10) - RMSE 9.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3wqw88Epd49",
        "colab_type": "text"
      },
      "source": [
        "*OBS: se neste caso estivéssemos usando a métrica r2 em vez da neg_mean_squared_error, possivelmente terímos valores negativos, uma vez que estamos usando cross validation e os dados não estão padronizados, sendo possível que a média dos dados de treino seja muito diferente da média dos dados de teste. A padronização dos dados neste caso resolveria este problema, gerando r2 entre 0 e 1.*\n",
        "\n",
        "Vamos agora verificar se a padronização de dados tem algum efeito nos resultados dos modelos, executando a mesma função, porém, padronizando os dados de X antes (uma boa prática!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtVjvBJwpBUC",
        "colab_type": "code",
        "outputId": "2db0546e-c64c-4c71-c73c-d09cd5f19f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "# Import das funções\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Padronização dos dados\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_padronizado = scaler.transform(X)\n",
        "\n",
        "comparaModelos(X_padronizado, Y, models)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression: MSE -34.71 (45.57) - RMSE 5.89\n",
            "Ridge: MSE -34.55 (45.42) - RMSE 5.88\n",
            "Lasso: MSE -37.87 (40.59) - RMSE 6.15\n",
            "ElasticNet: MSE -37.30 (36.08) - RMSE 6.11\n",
            "KNN: MSE -28.59 (25.46) - RMSE 5.35\n",
            "CART: MSE -39.05 (31.42) - RMSE 6.25\n",
            "SVM: MSE -38.52 (37.92) - RMSE 6.21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMD/j9UV54k8weXGQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZjfUMOlQbGy",
        "colab_type": "text"
      },
      "source": [
        "# Tuning Automático de Hiperparâmetros\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH0LiGrckXfw",
        "colab_type": "text"
      },
      "source": [
        "Podemos avaliar de forma fácil diversas variações de parâmetros de algoritmos usando a função GridSearchCV. Para tal, vamos criar uma função de tuning que recebe um modelo e um conjunto de parâmetros. Esta função irá imprimir o modelo com o melhor resultado.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si1U1tV_QiRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def tuningHiperparametros(nome, modelo, param_grid):\n",
        "\n",
        "  scoring = 'neg_mean_squared_error' # Virá com valor negativo!\n",
        "  \n",
        "  # Definição do número de folds \n",
        "  num_folds = 10\n",
        "  seed = 7\n",
        "    \n",
        "  # Definindo os folds\n",
        "  kfold = KFold(num_folds, True, random_state = seed)\n",
        "\n",
        "  # Avaliação de todas as combinações\n",
        "  grid = GridSearchCV(estimator=modelo, param_grid=param_grid, scoring=scoring, cv=kfold,\n",
        "      iid=True)\n",
        "  grid.fit(X_padronizado, Y)\n",
        "\n",
        "  # Imprime o modelo com o melhor resultado\n",
        "  print(\"Modelo %s - Melhor com %s\" % (nome, grid.best_params_)) \n",
        "  melhorModelo = grid.best_estimator_\n",
        "  \n",
        "  return melhorModelo;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXT2-EfrQ6yz",
        "colab_type": "code",
        "outputId": "2d00e976-59e5-4371-ebc2-0d3538b551ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "# Definição dos possíveis valores de hiperparâmetros para os Regressores Ridge, Lasso e ElasticNet\n",
        "alphas = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20, 50, 100]\n",
        "\n",
        "# Ridge\n",
        "param_gridRidge = dict(alpha=alphas)\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "melhorModeloRidge = tuningHiperparametros(\"Ridge\", Ridge(), param_gridRidge)\n",
        "\n",
        "# Lasso\n",
        "param_gridLasso = dict(alpha=alphas)\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "melhorModeloLasso = tuningHiperparametros(\"Lasso\", Lasso(), param_gridLasso)\n",
        "\n",
        "# ElasticNet\n",
        "param_gridElasticNet = dict(alpha=alphas)\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "melhorModeloElasticNet = tuningHiperparametros(\"ElasticNet\", ElasticNet(), param_gridElasticNet)\n",
        "\n",
        "# KNN\n",
        "# Definição dos possíveis valores de hiperparâmetros\n",
        "k = [1,3,5,7,9,11,13,15,17,19,21]\n",
        "distancias = [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
        "param_gridKNN = dict(n_neighbors=k, metric=distancias)\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "melhorModeloKNN = tuningHiperparametros(\"KNN\", KNeighborsRegressor(), param_gridKNN)\n",
        "\n",
        "# CART\n",
        "# Definição dos possíveis valores de hiperparâmetros\n",
        "criterios = ['mse', 'mae']\n",
        "max_depth = [3,5,10,20,30,40,50]\n",
        "min_samples_leaf = [3,5,10,20,30,40,50]\n",
        "param_gridCART = dict(criterion=criterios, min_samples_leaf=min_samples_leaf, max_depth=max_depth)\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "melhorModeloCART = tuningHiperparametros(\"CART\", DecisionTreeRegressor(), param_gridCART)\n",
        "\n",
        "# SVR\n",
        "# Definição dos possíveis valores de hiperparâmetros\n",
        "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "param_gridSVR = dict(C=c_values, kernel=kernel_values)\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "melhorModeloSVR = tuningHiperparametros(\"SVM\", SVR(gamma='auto'), param_gridSVR)\n",
        "\n",
        "models2 = []\n",
        "models2.append(('LinearRegression', LinearRegression())) # Não há muito o que variar\n",
        "models2.append(('Ridge', melhorModeloRidge))\n",
        "models2.append(('Lasso', melhorModeloLasso))\n",
        "models2.append(('ElasticNet', melhorModeloElasticNet))\n",
        "models2.append(('KNN', melhorModeloKNN))\n",
        "models2.append(('CART', melhorModeloCART))\n",
        "models2.append(('SVM', melhorModeloSVR))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "comparaModelos(X_padronizado, Y, models2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo Ridge - Melhor com {'alpha': 10}\n",
            "Modelo Lasso - Melhor com {'alpha': 0.01}\n",
            "Modelo ElasticNet - Melhor com {'alpha': 0.01}\n",
            "Modelo KNN - Melhor com {'metric': 'manhattan', 'n_neighbors': 3}\n",
            "Modelo CART - Melhor com {'criterion': 'mse', 'max_depth': 30, 'min_samples_leaf': 3}\n",
            "Modelo SVM - Melhor com {'C': 2.0, 'kernel': 'rbf'}\n",
            "\n",
            "\n",
            "LinearRegression: MSE -34.71 (45.57) - RMSE 5.89\n",
            "Ridge: MSE -33.48 (44.07) - RMSE 5.79\n",
            "Lasso: MSE -34.55 (45.60) - RMSE 5.88\n",
            "ElasticNet: MSE -34.30 (45.23) - RMSE 5.86\n",
            "KNN: MSE -28.73 (27.49) - RMSE 5.36\n",
            "CART: MSE -35.68 (28.98) - RMSE 5.97\n",
            "SVM: MSE -31.55 (32.87) - RMSE 5.62\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}