{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - 5. Ensembles_FeatureSelection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llw41FPOuOfM",
        "colab_type": "text"
      },
      "source": [
        "# Especialização em Ciência de Dados - PUC-Rio\n",
        "# Machine Learning\n",
        "## Ensembles e Seleção de Atributos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCBbRV0TuFfg",
        "colab_type": "text"
      },
      "source": [
        "# Importação dos dados\n",
        "Usaremos a mesma base de dados que trabalhamos anteriormente, o dataset Pima Indians Diabetes. O trecho de código a seguir é similar ao que fizemos em laboratórios anteriores (exceto pela padronização dos dados) e serve apenas para importar os dados e separá-los em entradas (X) e saídas (Y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J4CfumWuCKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega arquivo csv usando Pandas usando uma URL\n",
        "\n",
        "# Importa todo o pacote Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Importa a função datasets\n",
        "from sklearn import datasets\n",
        "\n",
        "# Importa a função scale\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# Informa o cabeçalho das colunas\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "# Lê o arquivo utilizando as colunas informadas\n",
        "dataset = pd.read_csv(url, names=colunas, skiprows=0, delimiter=',')\n",
        "\n",
        "# Pega apenas os dados do dataset e guardando em um array\n",
        "array = dataset.values\n",
        "\n",
        "# Separa o array em variáveis preditoras (X) e variável target (Y)\n",
        "# Coloca os dados na mesma escala (padronização)\n",
        "X = scale(array[:,0:8])\n",
        "Y = array[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRm0Yno8LBWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=10, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VDjF2J4KL0L",
        "colab_type": "text"
      },
      "source": [
        "# Ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHMpRPEWMF9z",
        "colab_type": "text"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp7P3X-xLJ_C",
        "colab_type": "text"
      },
      "source": [
        "### Bagging com Árvores de Decisão\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
        "\n",
        "Vamos usar o classificador BaggingClassifier com modelos CART, criando um total de 100 árvores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NePN-WSyKL5z",
        "colab_type": "code",
        "outputId": "013802e6-13e1-4a48-ac1f-6776d376b5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "modelo = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed) \n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7694463431305537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtn9xmMxrHQP",
        "colab_type": "text"
      },
      "source": [
        "Também podemos usar outro modelo com o Bagging, como o KNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hERmms1Aqseb",
        "colab_type": "code",
        "outputId": "a05f18bb-2734-4788-ca4a-bf7be062c9cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "modelo = BaggingClassifier(base_estimator=KNeighborsClassifier(), random_state=seed) \n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7551777170198223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyzQOW8xLLFz",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest e Extra Tree Classifier\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
        "\n",
        "Iremos primeiro construir um modelo CART simples para comparação e, em seguida, construir um modelo RandomForest para usando a classe RandomForestClassifier e um modelo ExtraTrees usando a classe ExtraTreesClassifier.\n",
        "\n",
        "Para ambos os modelos ensemble, usaremos 100 árvores e pontos de divisão escolhidos com uma seleção randômica de 3 atributos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgGuI_wqt0E_",
        "colab_type": "code",
        "outputId": "8c878050-82a6-4f47-f6c4-e9a577323ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "modelo = DecisionTreeClassifier() \n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6965481886534518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njIjn_fE0Lmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_trees = 100\n",
        "max_features = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od-CSW5JLLNR",
        "colab_type": "code",
        "outputId": "67c23b70-d8d4-4dc3-aa66-32158f224b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelo = RandomForestClassifier(n_estimators=num_trees, max_features=max_features, random_state=seed) \n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7720779220779221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEwJtWLpuu8R",
        "colab_type": "code",
        "outputId": "89ff805e-6cf5-4f78-ac98-3b558b6f0024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "modelo = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features, random_state=seed) \n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7603725222146275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaVwKQy8MA9H",
        "colab_type": "text"
      },
      "source": [
        "## Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O14P7qbrMp9Q",
        "colab_type": "text"
      },
      "source": [
        "### Adaboost\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
        "\n",
        "Iremos criar um modelo AdaBoost para classificação usando a classe AdaBoostClassifier. Serão construídas 100 árvores de decisão em sequência usando o algoritmo AdaBoost. O AdaBoost pode ser utilizado com vários modelos base, mas quando o parâmetro base_estimator não é passado, ele usa o DecisionTreeClassifier como padrão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAAaAaJsMBF7",
        "colab_type": "code",
        "outputId": "a128d204-fc6e-4b0a-af13-8e2dea617c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "modelo = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7408407382091593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTatHTE5M237",
        "colab_type": "text"
      },
      "source": [
        "### Stochastic Gradient Boosting\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "Iremos criar um modelo Gradient Boosting para classificação usando a classe GradientBoostingClassifier. Serão construídas 100 árvores de decisão em sequência usando o algoritmo Gradient Boosting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMzcu7IMM2_E",
        "colab_type": "code",
        "outputId": "405738ed-234d-4b3e-f77e-5342cfbcde36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "modelo = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed) \n",
        "results = cross_val_score(modelo, X, Y, cv=kfold)\n",
        "print(results.mean()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7669002050580999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CatxtoAbipae",
        "colab_type": "text"
      },
      "source": [
        "## Voting Ensemble\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
        "\n",
        "Iremos criar um ensemble de votação para classificação usando a classe VotingClassifier. Serão combinadas as predições de regressão logística, CART e SVM para o mesmo problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xBJrttdipih",
        "colab_type": "code",
        "outputId": "f150739a-2c14-4847-b1a8-513a15d7d3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# create the sub models\n",
        "estimators = []\n",
        "modelo1 = LogisticRegression(solver='liblinear')\n",
        "estimators.append(('logistic', modelo1))\n",
        "modelo2 = DecisionTreeClassifier()\n",
        "estimators.append(('cart', modelo2))\n",
        "modelo3 = SVC(gamma='auto')\n",
        "estimators.append(('svm', modelo3))\n",
        "\n",
        "# create the ensemble model\n",
        "ensemble = VotingClassifier(estimators)\n",
        "results = cross_val_score(ensemble, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7733937115516063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sbTO3yIujT5",
        "colab_type": "text"
      },
      "source": [
        "# Seleção de Atributos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfXVAOSNqexr",
        "colab_type": "text"
      },
      "source": [
        "## Seleção Univariada\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
        "\n",
        "A função **SelectKBest()** pode ser usada com diversos testes estatísticos, para selecionar os atributos. Vamos usar o teste qui-quadrado e selecionar os 4 melhores atributos que podem ser usados como variáveis preditoras.\n",
        "\n",
        "> O teste estatístico qui-quadrado é aplicado a dados categóricos para avaliar o quão provável é que qualquer diferença absoluta observada aconteça ao **acaso**, verificando se a frequência absoluta **observada** de uma variável é significativamente diferente da distribuição de frequência absoluta **esperada**. *Para saber mais: https://pt.wikipedia.org/wiki/Teste_qui-quadrado_de_Pearson*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6zCh09WqYWH",
        "colab_type": "code",
        "outputId": "27887f3e-e2a5-49c1-df55-49badb2ff826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from numpy import set_printoptions\n",
        "\n",
        "# Função para seleção de atributos\n",
        "best_var = SelectKBest(score_func = chi2, k = 4)\n",
        "\n",
        "# Executa a função de pontuação em (X, Y) e obtém os atributos selecionados\n",
        "fit = best_var.fit(abs(X), Y)\n",
        "\n",
        "# Reduz X para os atributos selecionados\n",
        "features = fit.transform(X)\n",
        "\n",
        "# Resultados\n",
        "print('\\nNúmero original de atributos:', X.shape[1])\n",
        "print('\\nNúmero reduzido de atributos:', features.shape[1])\n",
        "\n",
        "# Exibe os atributos orginais\n",
        "print(\"\\nAtributos Originais:\", dataset.columns[0:8])\n",
        "\n",
        "# Exibe as pontuações de cada atributos e os 4 escolhidas (com as pontuações mais altas): plas, teste, massa e idade.\n",
        "# (Basta mapear manualmente o índice dos nomes dos respectivos atributos)\n",
        "set_printoptions(precision=3)\n",
        "print(fit.scores_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Número original de atributos: 8\n",
            "\n",
            "Número reduzido de atributos: 4\n",
            "\n",
            "Atributos Originais: Index(['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age'], dtype='object')\n",
            "[ 6.605 11.619  3.63   7.452 17.004  0.572  3.687  0.478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSrheF65qu_Q",
        "colab_type": "text"
      },
      "source": [
        "## Eliminação Recursiva de Atributos\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
        "\n",
        "Iremos aplicar a técnica de eliminação recursiva de atributos com um algoritmo de Regressão Logística para selecionar as 3 melhores variáveis preditoras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tRYazhXqvK8",
        "colab_type": "code",
        "outputId": "e901ecbf-62ac-4365-838d-b8f27166a628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Criação do modelo\n",
        "modelo = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Eliminação Recursiva de Variáveis\n",
        "rfe = RFE(modelo, 3)\n",
        "fit = rfe.fit(X, Y)\n",
        "\n",
        "# Print dos resultados\n",
        "print(\"Atributos preditores:\", dataset.columns[0:8])\n",
        "# Exibe os atributos selecionados (marcados como True em \"Atributos Selecionados\" e com valor 1 em \"Ranking dos Atributos\"): preg, mass e pedi.\n",
        "# (Basta mapear manualmente o índice dos nomes dos respectivos atributos)\n",
        "print(\"\\nAtributos selecionados: %s\" % fit.support_)\n",
        "print(\"\\nRanking de atributos: %s\" % fit.ranking_)\n",
        "print(\"\\nQtd de melhores Atributos: %d\" % fit.n_features_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Atributos preditores: Index(['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age'], dtype='object')\n",
            "\n",
            "Atributos selecionados: [ True  True False False False  True False False]\n",
            "\n",
            "Ranking de atributos: [1 1 3 6 5 1 2 4]\n",
            "\n",
            "Qtd de melhores Atributos: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JByPx9rpyxpz",
        "colab_type": "text"
      },
      "source": [
        "## Análise de Componentes Principais (PCA)\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "Iremos aplicar a técnica de Análise de Componentes Principais selecionando 3 componentes principais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7quxKrjyxvN",
        "colab_type": "code",
        "outputId": "cc4ff44e-0e3f-4f44-e261-ef71777f119f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Função PCA\n",
        "pca = PCA(n_components=3)\n",
        "fit = pca.fit(X)\n",
        "\n",
        "# Resumo dos componentes - tem pouca semelhança com os dados de origem\n",
        "print(\"Porcentagem de variância explicada por cada um dos componentes: %s\" % fit.explained_variance_ratio_)\n",
        "print(\"\\n\", fit.components_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Porcentagem de variância explicada por cada um dos componentes: [0.262 0.216 0.129]\n",
            "\n",
            " [[ 0.128  0.393  0.36   0.44   0.435  0.452  0.271  0.198]\n",
            " [ 0.594  0.174  0.184 -0.332 -0.251 -0.101 -0.122  0.621]\n",
            " [-0.013  0.468 -0.535 -0.238  0.337 -0.362  0.433  0.075]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpqpF6Rs2BsE",
        "colab_type": "text"
      },
      "source": [
        "## Importância de Atributos\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
        "\n",
        "Iremos construir um classificador ExtraTreesClassifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1TMFLjU2BxQ",
        "colab_type": "code",
        "outputId": "316e4580-4320-44cc-801d-db863eca8441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Imports\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# Criação do modelo para seleção de atributos\n",
        "modelo = ExtraTreesClassifier(n_estimators=100)\n",
        "modelo.fit(X, Y)\n",
        "\n",
        "# Exibe a pontuação de importância para cada atributo (quanto maior a pontuação, mais importante é o atributo). Atributos selecionados: plas, idade e massa.\n",
        "print(modelo.feature_importances_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.112 0.231 0.099 0.08  0.077 0.138 0.122 0.142]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}