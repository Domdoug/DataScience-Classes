{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_8.Projeto completo de Classificação Binária.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mE4-PIaTAfKX",
        "f2OGe0DtAfU4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otEdveLq8Hn0",
        "colab_type": "text"
      },
      "source": [
        "# Especialização em Ciência de Dados - PUC-Rio\n",
        "# Machine Learning\n",
        "# Projeto completo de Classificação Binária"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1PEQEdZ9zm4",
        "colab_type": "text"
      },
      "source": [
        "## 1. Definição do Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDcdO4yx9db6",
        "colab_type": "text"
      },
      "source": [
        "O dataset usado neste projeto será o ***Sonar Mines vs Rocks***, disponível em https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks). \n",
        "\n",
        "O problema consiste em detectar se os objetos detectados pelo sonar são de metal ou de rocha. Cada exemplo contém 60 atributos numéricos no intervalo de 0.0 a 1.0. Cada número representa a energia dentro de uma determinada faixa de frequência, integrada durante um certo período de tempo. O rótulo associado a cada exemplo contém a letra R se o objeto é uma rocha e M se é um mina. Os números nos rótulos estão em ordem crescente de ângulo de aspecto, mas eles não codificam o ângulo diretamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcB0Efd-MS4",
        "colab_type": "text"
      },
      "source": [
        "## 2. Carga de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCn8CH4M7wF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import numpy\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import cm\n",
        "from pandas import read_csv\n",
        "from pandas import set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmHBahfF-cJL",
        "colab_type": "text"
      },
      "source": [
        "Faça download do dataset no site do repositório do UCI Machine Learning, salvando no diretório de trabalho local com o nome de arquivo sonar.all-data.csv.\n",
        "\n",
        "Não iremos especificar os nomes dos atributos porque eles ​​não têm nomes significativos. Também indicamos que não há informações de cabeçalho (header), para evitar que o código de carregamento de arquivo tome o primeiro registro como o nome da coluna. \n",
        "\n",
        "Com o dataset carregado, iremos explorá-lo um pouco."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJpWLh52-aPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carga do dataset\n",
        "url = 'sonar.all-data.csv'\n",
        "dataset = read_csv(url, header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBSgQt_z_TnV",
        "colab_type": "text"
      },
      "source": [
        "## 3. Análise de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqINv-wo_Xfe",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Estatísticas Descritivas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF3f00Zl_g7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensões do dataset\n",
        "print(dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dRVheWE_mJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tipos de cada atributo\n",
        "set_option('display.max_rows', 100) \n",
        "print(dataset.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ7FN2HL_s9h",
        "colab_type": "text"
      },
      "source": [
        "Agora, vamos dar uma olhada nas 20 primeiras linhas dos dados. Isso não mostra todas as colunas, mas podemos ver que todos os dados têm a mesma escala. Também podemos ver que o atributo de classe (60) possui valores de string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_sqnuG0_tD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# head\n",
        "set_option('display.width', 100) \n",
        "print(dataset.head(20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabLTz9c_tJE",
        "colab_type": "text"
      },
      "source": [
        "Analisando rapidamente os valores de classe, podemos ver que as classes são razoavelmente equilibradas entre M (minas) e R (rochas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j0Pa0W__tOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# distribuição das classes\n",
        "print(dataset.groupby(60).size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_5Ntt3f_tTv",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Visualizações Unimodais\n",
        "\n",
        "Vamos agora gerar visualizações dos atributos individualmente. \n",
        "\n",
        "Primeiro, vamos gerar os histogramas de cada atributo para ter uma ideia das distribuições de dados. Veremos que existem algumas distribuições do tipo Gaussiana e algumas distribuições do tipo exponencial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK3mK65T_tYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# histogramas\n",
        "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,8))\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kObO1uuU_teC",
        "colab_type": "text"
      },
      "source": [
        "Vamos dar uma olhada na mesma perspectiva dos dados usando gráficos de densidade. Veremos que muitos dos atributos têm uma distribuição distorcida. Uma transformação como a Box-Cox que pode aproximar a distribuição de uma Normal pode ser útil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUaJJNK_tji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# density plots\n",
        "dataset.plot(kind='density', subplots=True, layout=(8,8), sharex=False, legend=True, fontsize=1, figsize=(12,8))\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMMGbjYbAe-3",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Visualizações Multimodais\n",
        "\n",
        "Ao visualizar as correlações entre os atributos, perceberemos que parece haver alguma estrutura na ordem dos atributos. O azul ao redor da diagonal sugere que os atributos que estão próximos um do outro são geralmente mais correlacionados entre si. Os vermelhos também sugerem alguma correlação negativa moderada, a medida que os atributos estão mais distantes um do outro na ordenação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB612g0aAfE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matriz de Correlação\n",
        "fig = pyplot.figure(figsize=(12,8))\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none', cmap=cm.get_cmap('RdBu')) \n",
        "fig.colorbar(cax)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE4-PIaTAfKX",
        "colab_type": "text"
      },
      "source": [
        "## 4. Pré-Processamento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoLQBjKl9JVD",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Conjunto de validação\n",
        "\n",
        "É uma boa prática usar um conjunto de validação (na literatura também chamado de conjunto de testes), uma amostra dos dados que não será usada para a modelagem, mas somente no fim do projeto para confirmar a precisão do  modelo final. É um teste  que podemos usar para verificar se erramos e para nos dar confiança nas estimativas em dados não vistos. Usaremos 80% do conjunto de dados para modelagem e guardaremos 20% para validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEiAm3LEAfPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separação em conjuntos de treino e validação\n",
        "array = dataset.values\n",
        "X = array[:,0:60].astype(float)\n",
        "Y = array[:,60]\n",
        "validation_size = 0.20\n",
        "seed = 7\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n",
        "    test_size=validation_size, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OGe0DtAfU4",
        "colab_type": "text"
      },
      "source": [
        "## 5. Modelos de Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHzQpbX9QQh",
        "colab_type": "text"
      },
      "source": [
        "### 5.1. Criação e avaliação de modelos: linha base\n",
        "\n",
        "Não sabemos quais modelos performarão bem neste conjunto de dados. A intuição sugere que algoritmos baseados em distância, como KNN e SVM podem se sair bem. \n",
        "\n",
        "Para testar, usaremos a validação cruzada 10-fold e avaliaremos os modelos usando a métrica de acurácia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foy4MFlSAfaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parâmetros\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "scoring = 'accuracy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2C7w1OSAffj",
        "colab_type": "text"
      },
      "source": [
        "Vamos criar uma linha base de desempenho para esse problema e verificar vários modelos diferentes com suas configurações padrão: Regressão Logística, Árvores de classificação e regressão (CART), Máquinas de vetores de suporte (SVM), Naive Bayes (NB) e k-vizinhos mais próximos (KNN)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAhfSnnIAfke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criação dos modelos\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='liblinear'))) \n",
        "models.append(('KNN', KNeighborsClassifier())) \n",
        "models.append(('CART', DecisionTreeClassifier())) \n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC(gamma='auto')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eXEfVJCBQj4",
        "colab_type": "text"
      },
      "source": [
        "Agora vamos comparar os modelos, exibindo a acurácia média e o desvio padrão de cada um:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUUqbS2fBQrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avaliação dos modelos\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "  kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgVTq2DXBQxw",
        "colab_type": "text"
      },
      "source": [
        "Os resultados sugerem que tanto a regressão logística quanto os vizinhos mais próximos k podem ser bons modelos, mas estes são apenas valores médios de acurácia, sendo também prudente observar a distribuição dos resultados de cada fold da validação cruzada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQvttrIBQ3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparação dos modelos\n",
        "fig = pyplot.figure() \n",
        "fig.suptitle('Comparação dos Modelos') \n",
        "ax = fig.add_subplot(111) \n",
        "pyplot.boxplot(results) \n",
        "ax.set_xticklabels(names) \n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n63s9EyxBQ9w",
        "colab_type": "text"
      },
      "source": [
        "Os resultados mostram uma distribuição restrita para o KNN, o que é encorajador, sugerindo baixa variação. Os maus resultados para o SVM são surpreendentes.\n",
        "\n",
        "É possível que a distribuição variada dos atributos esteja afetando a acurácia de algoritmos como o SVM. A seguir, repetiremos este processo usando uma cópia padronizada do conjunto de dados de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olo7SPk2BvvW",
        "colab_type": "text"
      },
      "source": [
        "### 5.2. Criação e avaliação de modelos: dados padronizados\n",
        "\n",
        "Como suspeitamos que as diferentes distribuições dos dados brutos possam impactar negativamente a habilidade de alguns modelos, vamos agora utilizar cópia padronizada do dataset. Os dados serão transformados de modo que cada atributo tenha média 0 e um desvio padrão 1. \n",
        "\n",
        "Para evitar o \"vazamento de dados\" na transformação, vamos usar pipelines que padronizam os dados e constroem o modelo para cada fold de teste de validação cruzada. Dessa forma, podemos obter uma estimativa justa de como cada modelo com dados padronizados pode funcionar com dados não vistos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmQbiYQdBRDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Padronização do dataset\n",
        "pipelines = []\n",
        "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression(solver='liblinear'))]))) \n",
        "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
        "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n",
        "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])))\n",
        "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC(gamma='auto'))])))\n",
        "results = []\n",
        "names = []\n",
        "for name, model in pipelines:\n",
        "  kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvqaMjLRBRJE",
        "colab_type": "text"
      },
      "source": [
        "Analisando os resultados, vemos que o KNN ainda está indo bem, ainda melhor do que antes. Também podemos ver que a padronização dos dados levou o SVM para o melhor modelo testado até agora.\n",
        "\n",
        "Vamos analisar estes resultados graficamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBcjd2uDBROs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparação dos modelos com dados padronizados\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Comparação dos modelos com dados padronizados') \n",
        "ax = fig.add_subplot(111) \n",
        "pyplot.boxplot(results) \n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZFd3ZkNCE_F",
        "colab_type": "text"
      },
      "source": [
        "Os resultados sugerem que aprofundemos os modelos SVM e KNN, sendo muito provável que outras configurações possam render modelos ainda mais precisos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-f2vCU5CMmp",
        "colab_type": "text"
      },
      "source": [
        "### 5.3. Ajuste dos Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vSn0trh9V6E",
        "colab_type": "text"
      },
      "source": [
        "#### Ajuste do KNN\n",
        "Podemos começar ajustando o número de vizinhos e as métricas de distância para o KNN. Tentaremos todos os valores ímpares de k de 1 a 21 e as métricas de distância euclideana, manhattan e minkowski. Cada valor de k e de distância será avaliado usando a validação cruzada 10-fold no conjunto de dados padronizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwI7Cxc-CZdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuning do KNN\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "\n",
        "k = [1,3,5,7,9,11,13,15,17,19,21]\n",
        "distancias = [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
        "param_grid = dict(n_neighbors=k, metric=distancias)\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold, iid=True)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Melhor: %f usando %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) com: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPXRycKOCikN",
        "colab_type": "text"
      },
      "source": [
        "Vimos que a melhor configuração tem k = 1. Isso é interessante, pois o algoritmo fará previsões usando a instância mais semelhante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFhy-staCmo8",
        "colab_type": "text"
      },
      "source": [
        "#### Ajuste do SVM\n",
        "Iremos ajustar dois parâmetros principais do algoritmo SVM, o valor de C (o quanto flexibilizar a margem) e o tipo de kernel. O padrão para o SVM (a classe SVC) é usar o kernel da Função Base Base Radial (RBF) com um valor C definido como 1.0. Cada combinação de valores será avaliada usando a validação cruzada 10-fold no conjunto de dados padronizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YvUNoSECsAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuning do KNN\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "\n",
        "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "param_grid = dict(C=c_values, kernel=kernel_values)\n",
        "\n",
        "model = SVC(gamma='auto')\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold, iid=True)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4od0DCSCyvG",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver que a configuração com maior acurácia foi o SVM com kernel RBF e C = 1,5. A melhor acurácia é aparentemente melhor do que o que o KNN poderia alcançar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU9iNMzIC2ac",
        "colab_type": "text"
      },
      "source": [
        "## 6. Métodos Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "our40Y5t9gms",
        "colab_type": "text"
      },
      "source": [
        "Outra maneira de melhorar o desempenho dos algoritmos é usar métodos de ensemble. Avaliaremos quatro modelos diferentes, sendo dois métodos de Boosting e dois de Bagging:\n",
        "* Métodos de Boosting: AdaBoost (AB) e Gradient Boosting (GBM).\n",
        "* Métodos de Bagging: Random Forests (RF) e Extra Trees (ET).\n",
        "\n",
        "Usaremos novamente a validação cruzada 10-fold. Nenhuma padronização de dados será usada neste caso porque todos os quatro algoritmos de conjunto são baseados em árvores de decisão, que são modelos menos sensíveis às distribuições de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83D_EEm7DETB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensembles\n",
        "\n",
        "ensembles = []\n",
        "ensembles.append(('AB', AdaBoostClassifier())) \n",
        "ensembles.append(('GBM', GradientBoostingClassifier())) \n",
        "ensembles.append(('RF', RandomForestClassifier(n_estimators=10))) \n",
        "ensembles.append(('ET', ExtraTreesClassifier(n_estimators=10))) \n",
        "results = []\n",
        "names = []\n",
        "for name, model in ensembles:\n",
        "  kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqGPumb7DJw3",
        "colab_type": "text"
      },
      "source": [
        "Vamos comparar os resultados graficamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5dsrOLwDJ26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparação de modelos\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Comparação de modelos Ensemble') \n",
        "ax = fig.add_subplot(111) \n",
        "pyplot.boxplot(results) \n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9hQXKXWDPTG",
        "colab_type": "text"
      },
      "source": [
        "Os resultados sugerem que o GBM e o ET são provavelmente, os melhores modelos, podendo ser ainda aprimorados com variações de parâmetros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUpaYcwDRDt",
        "colab_type": "text"
      },
      "source": [
        "## 7. Finalização do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpopPk1x9mTY",
        "colab_type": "text"
      },
      "source": [
        "Neste estudo, o SVM foi o modelo que mostrou melhor acurácia, melhor estabilidade, além de ser um modelo de baixa complexidade para este problema. \n",
        "\n",
        "Finalizaremos o modelo treinando-o em todo o conjunto de dados de treinamento e faremos predições para o conjunto de dados de validação (separado anteriormente)para confirmar nossas descobertas. \n",
        "\n",
        "Até o momento, vimos que o SVM tem um desempenho melhor quando o conjunto de dados é padronizado. Assim, iremos padronizar todo o conjunto de dados de treinamento e depois, aplicar a mesma transformação aos atributos de entrada do conjunto de dados de validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbrFxAbSDVIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparação do modelo\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "model = SVC(C=1.5)\n",
        "model.fit(rescaledX, Y_train)\n",
        "\n",
        "# Estimativa da acurácia no conjunto de validação\n",
        "rescaledValidationX = scaler.transform(X_validation)\n",
        "predictions = model.predict(rescaledValidationX)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W7I4j7hDZyE",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver que alcançamos uma acurácia de quase 86% no conjunto de dados de validação, uma pontuação que se aproxima das nossas expectativas estimadas durante o ajuste do SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajCN3RywDdi9",
        "colab_type": "text"
      },
      "source": [
        "## Resumo\n",
        "\n",
        "Trabalhamos com um problema de aprendizado de máquina de modelagem preditiva de classificação de ponta a ponta. As etapas abordadas foram:\n",
        "\n",
        "* Definição do problema (dados de retorno do sonar).\n",
        "* Carga dos dados\n",
        "* Análise dos dados (mesma escala, mas distribuições diferentes de dados).\n",
        "* Avaliação de modelos (o KNN parecia bom).\n",
        "* Avaliação de modelos com padronização (KNN e SVM pareciam bons).\n",
        "* Ajuste dos modelos (K = 1 para KNN foi bom, SVM com um núcleo RBF e C = 1.5 foi melhor).\n",
        "* Métodos de ensemble (bagging e boosting, não performaram tão bem quanto SVM).\n",
        "* Finalização do modelo (use todos os dados de treinamento e valide usando o conjunto de dados de validação)."
      ]
    }
  ]
}