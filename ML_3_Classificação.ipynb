{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "ML - 3. Classificação.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKd9KtCqC-Yx",
        "colab_type": "text"
      },
      "source": [
        "# Especialização em Ciência de Dados - PUC-Rio\n",
        "# Machine Learning\n",
        "## Problemas de Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xZzCmv2TgJw",
        "colab_type": "text"
      },
      "source": [
        "# Importação dos dados\n",
        "\n",
        "Usaremos a mesma base de dados que trabalhamos anteriormente, o dataset Pima Indians Diabetes. O trecho de código a seguir é idêntico ao que fizemos no laboratório passado e serve apenas para importar os dados e separá-los em entradas (X) e saídas (Y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyrucq_ZPgWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega arquivo csv usando Pandas usando uma URL\n",
        "\n",
        "# Importa todo o pacote Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Importa a função datasets\n",
        "from sklearn import datasets\n",
        "\n",
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# Informa o cabeçalho das colunas\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "# Lê o arquivo utilizando as colunas informadas\n",
        "dataset = pd.read_csv(url, names=colunas, skiprows=0, delimiter=',')\n",
        "\n",
        "# Pega apenas os dados do dataset e guardando em um array\n",
        "array = dataset.values\n",
        "\n",
        "# Separa o array em variáveis preditoras (X) e variável target (Y)\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj6aMXAwB3Xy",
        "colab_type": "text"
      },
      "source": [
        "O trecho de código a seguir ilustra como importar um dos datasets que já vem junto com o scikit-learn. São eles:\n",
        "\n",
        "* load_boston([return_X_y])\t- **boston house-prices** (regressão).\n",
        "* load_iris([return_X_y])\t- **iris** (classificação).\n",
        "* load_diabetes([return_X_y])\t- **diabetes** (regressão).\n",
        "* load_digits([n_class, return_X_y]) - **digits** (classificação).\n",
        "* load_linnerud([return_X_y])\t- **linnerud** (regressão multivariada).\n",
        "* load_wine([return_X_y])\t- **wine** (classificação).\n",
        "* load_breast_cancer([return_X_y]) - **breast cancer wisconsin** (classificação)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUGGIIi4l3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NÃO EXECUTAR PARA O LABORATÓRIO!\n",
        "\n",
        "# Datasets do scikit-learn: https://scikit-learn.org/stable/datasets/index.html\n",
        "\n",
        "# Importação de pacotes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "# Carrega o dataset iris\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Converte para dataframe\n",
        "dataframe = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "\n",
        "# Mostra as 5 primeiras linhas do dataset\n",
        "dataframe.head(5)\n",
        "\n",
        "# Extraindo os 2 primeiros atributos para variáveis preditoras (x) e variável target (y)\n",
        "x_iris = iris.data[:, :2] \n",
        "y_iris = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qySAU0LTT-jS",
        "colab_type": "text"
      },
      "source": [
        "# Resampling: Particionamento do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd2NJcDuUMKc",
        "colab_type": "text"
      },
      "source": [
        "## Particionamento em Conjuntos de Treino e Teste\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3JMZK2yUQXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dos pacotes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definição do tamanho do conjunto de teste para 33%\n",
        "teste_size = 0.33\n",
        "\n",
        "# A semente (seed) pode ser qualquer número, e garante que os resultados possam ser reproduzidos de forma idêntica toda vez que o script for rodado. \n",
        "# Isto é muito importante quando trabalhamos com modelos ou métodos que utilizam de algum tipo de aleatoriedade.\n",
        "seed = 7\n",
        "\n",
        "# Criando os conjuntos de dados de treino e de teste\n",
        "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uhVY0CTUfgh",
        "colab_type": "text"
      },
      "source": [
        "## Validação Cruzada (K-fold Cross-Validation)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWHtCNPWUh39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avaliação usando Cross Validation\n",
        "\n",
        "# Import dos pacotes\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Definição dos valores para os folds e seed\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "\n",
        "# Definindo os folds\n",
        "kfold = KFold(num_folds, True, random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nccHlXHIVkme",
        "colab_type": "text"
      },
      "source": [
        "# Métricas de Avaliação para Problemas de Classificação\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html\n",
        "\n",
        "http://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTRTklGlVF_m",
        "colab_type": "text"
      },
      "source": [
        "Para ilustrar as métricas, precisaremos criar um modelo qualquer. Vamos usar a Regressão Logística."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rstehFP3VKwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo = LogisticRegression(solver='liblinear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4rfmztgWLda",
        "colab_type": "text"
      },
      "source": [
        "## Acurácia\n",
        "\n",
        "**Acurácia = número de previsões corretas/todas as previsões**\n",
        "\n",
        "É a métrica de avaliação mais comum para problemas de classificação, mas é também a mais mal utilizada. Ela só é adequada quando as classes são equilibradas e que todos os erros de previsão são igualmente importantes, o que geralmente não é o caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17ReNdGBWLk6",
        "colab_type": "code",
        "outputId": "3bcf0874-fe3a-4ddc-efa6-f163fc67f366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### 1. Usando validação cruzada\n",
        "\n",
        "# Calculando a acurácia usando o modelo criado anteriormente\n",
        "resultado = cross_val_score(modelo, X, Y, cv = kfold, scoring = 'accuracy')\n",
        "\n",
        "# Print dos resultados\n",
        "print(\"Acurácia de teste: %.2f%%\" % (resultado.mean() * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia de teste: 77.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itAu7qiYUVuf",
        "colab_type": "code",
        "outputId": "e5e131c3-a12a-4cdf-d49f-fa943dd2bb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### 2. Usando conjuntos de treino e teste\n",
        "\n",
        "# Treinamento do modelo criado anteriormente\n",
        "modeloTreinado = modelo.fit(X_treino, Y_treino)\n",
        "\n",
        "# Previsões\n",
        "Y_pred = modeloTreinado.predict(X_teste)\n",
        "\n",
        "# Resultados\n",
        "corretas = (Y_teste == Y_pred).sum()\n",
        "total = Y_teste.shape[0]\n",
        "\n",
        "# Print dos resultados\n",
        "print(\"Acurácia com particionamento treino-teste: %.2f%%\" % (corretas / total * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia com particionamento treino-teste: 75.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxMV5kxoWXM8",
        "colab_type": "text"
      },
      "source": [
        "## Área sobre a curva ROC (AUC)\n",
        "\n",
        "Métrica de performance para classificação binária, em que podemos definir as classes em positiavs e negativas. Estes problemas são um *trade-off* entre Sensitivity (Sensibilidade) e Specifity (Especificidade).\n",
        "* Sensitivity: a taxa de verdadeiros positivos (TP). Número de instâncias positivas da primeira classe que foram previstas corretamente.\n",
        "* Specifity: a taxa de verdadeiros negativos (TN). Número de instâncias da segunda classe que foram previstas corretamente.\n",
        "\n",
        "Valores acima de 0.5 indicam uma boa taxa de previsão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1C6t6rmWXRu",
        "colab_type": "code",
        "outputId": "ec94e3cf-28e7-4bea-f3f3-71bbaedc735e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculando a AUC usando a validação cruzada e o modelo criado anteriormente\n",
        "resultado = cross_val_score(modelo, X, Y, cv = kfold, scoring = 'roc_auc')\n",
        "\n",
        "# Print do resultado\n",
        "print(\"AUC: %.2f%%\" % (resultado.mean() * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 82.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znJ8Y44Lvo9S",
        "colab_type": "text"
      },
      "source": [
        "## Combinando métricas\n",
        "\n",
        "Com a biblioteca cross_validate é possível exibir diversas métricas, incluindo as métricas de treino e teste. Veja mais em: \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
        "\n",
        "A lista de métricas suportadas está disponível em: \n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSyDFEI9uAtO",
        "colab_type": "code",
        "outputId": "1b4a4810-2b24-4403-9cd2-8d962c8bd82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Import da função\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Calculando a acurácia e a AUC usando a validação cruzada e o modelo criado anteriormente\n",
        "resultado = cross_validate(modelo, X, Y, cv = kfold,\n",
        "                        scoring=('accuracy', 'roc_auc'),\n",
        "                        return_train_score=True)\n",
        "   \n",
        "print(\"train_accuracy: %.2f%%\" % ((resultado['train_accuracy'].mean()) * 100) )\n",
        "print(\"test_accuracy: %.2f%%\" % ((resultado['test_accuracy'].mean()) * 100) )\n",
        "print(\"train_roc_auc: %.2f%%\" % ((resultado['train_roc_auc'].mean()) * 100) )\n",
        "print(\"test_roc_auc: %.2f%%\" % ((resultado['test_roc_auc'].mean()) * 100) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy: 77.79%\n",
            "test_accuracy: 77.09%\n",
            "train_roc_auc: 83.63%\n",
            "test_roc_auc: 82.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf-20UVMWsqH",
        "colab_type": "text"
      },
      "source": [
        "## Matriz de Confusão\n",
        "\n",
        "Como a matriz de confusão não é uma métrica única, ela não é suportada pelas funções *cross_val_score* e *cross_validate*. É mais fácil gerá-la usando o particionamento em conjuntos de treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5pgLXS5Wvf7",
        "colab_type": "code",
        "outputId": "a6b0cf1d-c37e-4806-ed31-0ec8e981d7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Matriz de Confusão\n",
        "\n",
        "# Import da função\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Resultado do modelo nos dados de teste \n",
        "previsoes = modelo.predict(X_teste)\n",
        "matrix = confusion_matrix(Y_teste, previsoes) \n",
        "print(matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[141  21]\n",
            " [ 41  51]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MgpBDOBW_Mg",
        "colab_type": "text"
      },
      "source": [
        "## Relatório de Métricas de Classificação do scikit-learn\n",
        "\n",
        "O scikit-learn também disponibiliza uma função que gera um relatório de métricas, a *classification_report*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUX-crAKXFE_",
        "colab_type": "code",
        "outputId": "be0ade10-5fdd-41f7-a9a3-66ed430fad75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Import da função\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Criação do relatório\n",
        "report = classification_report(Y_teste, previsoes) \n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.87      0.82       162\n",
            "         1.0       0.71      0.55      0.62        92\n",
            "\n",
            "    accuracy                           0.76       254\n",
            "   macro avg       0.74      0.71      0.72       254\n",
            "weighted avg       0.75      0.76      0.75       254\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay-Lkdj9TyFf",
        "colab_type": "text"
      },
      "source": [
        "# Algoritmos de Classificação\n",
        "\n",
        "Vamos criar uma função de treinamento e avaliação que será usada em todos os modelos, para evitar duplicação de código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz9iObHSzuK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "### Treinamento e avaliação do modelo\n",
        "\n",
        "def treinarAvaliarModelo (modelo):\n",
        "\n",
        "    ## 1. Usando validação cruzada\n",
        "\n",
        "    print(\"=== Usando validação cruzada ===\")\n",
        "\n",
        "    # Aplicação do modelo e cálculo dos resultados\n",
        "    resultado = cross_validate(modelo, X, Y, cv = kfold,\n",
        "                            scoring=('accuracy', 'roc_auc'),\n",
        "                            return_train_score=True)\n",
        "\n",
        "    print(\"Acurácia de treino: %.2f%%\" % ((resultado['train_accuracy'].mean()) * 100) )\n",
        "    print(\"Acurácia de teste: %.2f%%\" % ((resultado['test_accuracy'].mean()) * 100) )\n",
        "    print(\"AUC de treino: %.2f%%\" % ((resultado['train_roc_auc'].mean()) * 100) )\n",
        "    print(\"AUC de teste: %.2f%%\" % ((resultado['test_roc_auc'].mean()) * 100) )\n",
        "    print(\"\\n\")\n",
        "\n",
        "    ## 2. Usando conjuntos de treino e teste em vez de validação cruzada\n",
        "    \n",
        "    print(\"=== Usando particionamento treino-teste ===\")\n",
        "\n",
        "    # Treinamento\n",
        "    modeloTreinado = modelo.fit(X_treino, Y_treino)\n",
        "\n",
        "    # Previsões\n",
        "    Y_pred = modeloTreinado.predict(X_teste)\n",
        "\n",
        "    # Resultados\n",
        "    corretas = (Y_teste == Y_pred).sum()\n",
        "    total = Y_teste.shape[0]\n",
        "\n",
        "    # Print dos resultados   \n",
        "    print(\"Acurácia de teste: %.2f%%\" % (corretas / total * 100))\n",
        "    print(\"\\n\")\n",
        "    print(metrics.classification_report(Y_teste, Y_pred))\n",
        "    print(metrics.confusion_matrix(Y_teste, Y_pred))\n",
        "    \n",
        "    return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7qC1FiZ1YiK",
        "colab_type": "text"
      },
      "source": [
        "Relembrando...\n",
        "<ul>\n",
        "<li>Precision: Será que o que eu recuperei tem qualidade?</li>\n",
        "<li>Recall: Será que eu recuperei tudo que deveria recuperar ?</li>\n",
        "<li>F1-score: Faz uma media harmonica entre os dois</li>\n",
        "<li>Support: Qtd de registros do conjunto que se enquadram na classificação</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfZYelelPNq5",
        "colab_type": "text"
      },
      "source": [
        "## Árvores de Decisão\n",
        "\n",
        "Os modelos de árvores de decisão constroem uma árvore binária a partir dos dados de treinamento. Os pontos de divisão são escolhidos através da avaliação dos dados de treinamento, com base na contribuição de cada atributo para minimizar uma função de custo (como, por exemplo, o índice Gini, usado para medir a probabilidade de dois itens aleatórios pertencerem à mesma classe). Para construir um modelo do tipo CART (Classification and Regression Trees), podemos usar a classe DecisionTreeClassifier.\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pgqDU5n2ykR",
        "colab_type": "text"
      },
      "source": [
        "**OBS:**\n",
        "Quais são os vários algoritmos da árvore de decisão e como eles diferem um do outro? Qual é implementado no scikit-learn?\n",
        "\n",
        "* ID3 (Iterative Dichotomiser 3) foi desenvolvido em 1986 por Ross Quinlan. O algoritmo cria uma árvore de múltiplas vias, encontrando para cada nó (isto é, de maneira gulosa) o recurso categórico que produzirá o maior ganho de informação para os alvos categóricos. As árvores crescem no tamanho máximo e, em seguida, geralmente é aplicada uma etapa de poda para melhorar a capacidade da árvore de generalizar para dados não vistos.\n",
        "\n",
        "* C4.5 é o sucessor do ID3 e removeu a restrição de que os recursos devem ser categóricos, definindo dinamicamente um atributo discreto (com base em variáveis numéricas) que particiona o valor do atributo contínuo em um conjunto discreto de intervalos. C4.5 converte as árvores treinadas (ou seja, a saída do algoritmo ID3) em conjuntos de regras if-then. Essa precisão de cada regra é então avaliada para determinar a ordem em que elas devem ser aplicadas. A poda é feita removendo a pré-condição de uma regra se a precisão da regra melhorar sem ela.\n",
        "\n",
        "* C5.0 é o lançamento de uma versão mais recente da C4.5 sob uma licença proprietária. Ele usa menos memória e cria conjuntos de regras menores que o C4.5, sendo mais preciso.\n",
        "\n",
        "* CART (Classification and Regression Trees) é muito semelhante ao C4.5, mas difere no fato de suportar variáveis de saída numéricas (problemas de regressão) e não computar conjuntos de regras. O CART constrói árvores binárias usando os atributos que produzem o maior ganho de informação em cada nó.\n",
        "\n",
        "**O scikit-learn usa uma versão otimizada do algoritmo CART; no entanto, a implementação do scikit-learn não suporta variáveis categóricas por enquanto.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRfMvDfkQhps",
        "colab_type": "code",
        "outputId": "1439cc94-8d8b-4494-a37d-a942ffc24c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Árvore de Classificação CART\n",
        "\n",
        "# Import da função\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Escolhendo o modelo\n",
        "modelo = DecisionTreeClassifier()\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
            "                       max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort=False,\n",
            "                       random_state=None, splitter='best')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 100.00%\n",
            "Acurácia de teste: 69.15%\n",
            "AUC de treino: 100.00%\n",
            "AUC de teste: 65.82%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 71.26%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.78      0.78       162\n",
            "         1.0       0.60      0.60      0.60        92\n",
            "\n",
            "    accuracy                           0.71       254\n",
            "   macro avg       0.69      0.69      0.69       254\n",
            "weighted avg       0.71      0.71      0.71       254\n",
            "\n",
            "[[126  36]\n",
            " [ 37  55]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHBuprcqzSVP",
        "colab_type": "text"
      },
      "source": [
        "Também é possível especificar valores para os parâmetros da árvore de classificação:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pyropeHy20S",
        "colab_type": "code",
        "outputId": "ab30826e-4b28-4d71-ef36-f4128fa3b863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Criando o modelo já com os parâmetros desejados\n",
        "modelo = DecisionTreeClassifier(max_depth = None, \n",
        "                             max_features = None, \n",
        "                             criterion = 'entropy', \n",
        "                             min_samples_leaf = 1, \n",
        "                             min_samples_split = 2)\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
            "                       max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort=False,\n",
            "                       random_state=None, splitter='best')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 100.00%\n",
            "Acurácia de teste: 68.76%\n",
            "AUC de treino: 100.00%\n",
            "AUC de teste: 66.07%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 71.26%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.80      0.78       162\n",
            "         1.0       0.61      0.55      0.58        92\n",
            "\n",
            "    accuracy                           0.71       254\n",
            "   macro avg       0.69      0.68      0.68       254\n",
            "weighted avg       0.71      0.71      0.71       254\n",
            "\n",
            "[[130  32]\n",
            " [ 41  51]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu5fJcry1_g1",
        "colab_type": "text"
      },
      "source": [
        "É possível plotar a árvore gerada usando a função **plot_tree**. Vamos ilustrar com o dataset Iris, que é menor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMMir3gc1pJm",
        "colab_type": "code",
        "outputId": "0f83b862-f8b6-441d-e88c-0a44c4534eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "iris = load_iris()\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(iris.data, iris.target)\n",
        "tree.plot_tree(clf.fit(iris.data, iris.target)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 199.32, 'X[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
              " Text(141.64615384615385, 163.07999999999998, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
              " Text(193.15384615384616, 163.07999999999998, 'X[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
              " Text(103.01538461538462, 126.83999999999999, 'X[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
              " Text(51.50769230769231, 90.6, 'X[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
              " Text(25.753846153846155, 54.359999999999985, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
              " Text(77.26153846153846, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
              " Text(154.52307692307693, 90.6, 'X[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
              " Text(128.76923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
              " Text(180.27692307692308, 54.359999999999985, 'X[0] <= 6.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
              " Text(154.52307692307693, 18.119999999999976, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
              " Text(206.03076923076924, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
              " Text(283.2923076923077, 126.83999999999999, 'X[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
              " Text(257.53846153846155, 90.6, 'X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
              " Text(231.7846153846154, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
              " Text(283.2923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
              " Text(309.04615384615386, 90.6, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igYpAtpLPNPk",
        "colab_type": "text"
      },
      "source": [
        "## KNN\n",
        "O algoritmo KNN usa uma métrica de distância para encontrar as k instâncias mais semelhantes nos dados de treinamento para uma nova instância e considera o resultado médio dos vizinhos como a previsão. Podemos construir um modelo KNN usando a classe KNeighborsClassifier.\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCKTOw0UPNXZ",
        "colab_type": "code",
        "outputId": "9f3888e9-b94a-4df7-cda5-d20881ce7654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# KNN\n",
        "\n",
        "# Import da função\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Escolhendo o modelo\n",
        "modelo = KNeighborsClassifier()\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 80.22%\n",
            "Acurácia de teste: 71.10%\n",
            "AUC de treino: 87.23%\n",
            "AUC de teste: 72.54%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 69.29%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.80      0.77       162\n",
            "         1.0       0.59      0.51      0.55        92\n",
            "\n",
            "    accuracy                           0.69       254\n",
            "   macro avg       0.66      0.65      0.66       254\n",
            "weighted avg       0.69      0.69      0.69       254\n",
            "\n",
            "[[129  33]\n",
            " [ 45  47]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLNOblkd1_Be",
        "colab_type": "text"
      },
      "source": [
        "Vamos agora experimentar variar alguns dos parâmetros do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX7Ow2bwvCsp",
        "colab_type": "code",
        "outputId": "692dbe7d-65e3-448b-91d7-f8b0e1294999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# Criação de outro modelo alterando o tipo de distância\n",
        "modelo = KNeighborsClassifier(metric = 'euclidean')\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Criação de outro modelo alterando o valor de k\n",
        "modelo = KNeighborsClassifier(n_neighbors = 7)\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 80.22%\n",
            "Acurácia de teste: 71.10%\n",
            "AUC de treino: 87.23%\n",
            "AUC de teste: 72.54%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 69.29%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.80      0.77       162\n",
            "         1.0       0.59      0.51      0.55        92\n",
            "\n",
            "    accuracy                           0.69       254\n",
            "   macro avg       0.66      0.65      0.66       254\n",
            "weighted avg       0.69      0.69      0.69       254\n",
            "\n",
            "[[129  33]\n",
            " [ 45  47]]\n",
            "\n",
            "\n",
            "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
            "                     weights='uniform')>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 78.73%\n",
            "Acurácia de teste: 73.05%\n",
            "AUC de treino: 85.99%\n",
            "AUC de teste: 75.65%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 68.50%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.77      0.76       162\n",
            "         1.0       0.57      0.53      0.55        92\n",
            "\n",
            "    accuracy                           0.69       254\n",
            "   macro avg       0.66      0.65      0.65       254\n",
            "weighted avg       0.68      0.69      0.68       254\n",
            "\n",
            "[[125  37]\n",
            " [ 43  49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8FkxRHvPNeR",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes\n",
        "O algoritmo Naive Bayes calcula a probabilidade de cada classe e a probabilidade condicional de cada classe, considerando cada valor de entrada. Essas probabilidades são estimadas para novos dados e multiplicadas juntas, assumindo que sejam todas independentes (uma suposição simples ou ingênua). Ao trabalhar com dados com valores reais, supõe-se que eles seguem uma distribuição Gaussiana. Podemos construir um modelo Naive Bayes usando a classe GaussianNB.\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvwFUtlMPNk1",
        "colab_type": "code",
        "outputId": "2078f63b-3157-4371-908f-c714b7916258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "# Import da função\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Escolhendo o modelo\n",
        "modelo = GaussianNB()\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=1e-09)>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 76.29%\n",
            "Acurácia de teste: 75.91%\n",
            "AUC de treino: 82.51%\n",
            "AUC de teste: 81.24%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 74.41%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.80      0.80       162\n",
            "         1.0       0.65      0.65      0.65        92\n",
            "\n",
            "    accuracy                           0.74       254\n",
            "   macro avg       0.72      0.72      0.72       254\n",
            "weighted avg       0.74      0.74      0.74       254\n",
            "\n",
            "[[129  33]\n",
            " [ 32  60]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRMGgPk-Q0EZ",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machines\n",
        "O SVM busca uma linha que melhor separa duas classes. As instâncias de dados mais próximas desta linha são chamadas vetores de suporte e influenciam onde a linha é colocada. O SVM foi estendido para suportar várias classes e é possível utilizar diferentes funções kernel. Por padrão, é usada e função de base radial. Vamos construir um modelo SVM usando a classe SVC.\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "http://scikit-learn.org/stable/modules/svm.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B1-PEmsQ3A1",
        "colab_type": "code",
        "outputId": "a2fd16b4-8b38-4a8e-91c6-8461e4e4d7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "# SVM com kernel linear\n",
        "\n",
        "# Import da função\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Escolhendo o modelo\n",
        "modelo = SVC(gamma='auto',kernel = 'linear')\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)\n",
        "\n",
        "# Imprimindo os vetores de suporte\n",
        "print(\"\\n\")\n",
        "print (modelo.support_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 77.62%\n",
            "Acurácia de teste: 77.08%\n",
            "AUC de treino: 83.90%\n",
            "AUC de teste: 82.73%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 78.35%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.89      0.84       162\n",
            "         1.0       0.75      0.60      0.67        92\n",
            "\n",
            "    accuracy                           0.78       254\n",
            "   macro avg       0.77      0.74      0.75       254\n",
            "weighted avg       0.78      0.78      0.78       254\n",
            "\n",
            "[[144  18]\n",
            " [ 37  55]]\n",
            "\n",
            "\n",
            "[  2   6  12  17  20  25  27  29  35  43  46  47  54  59  60  63  65  73\n",
            "  74  78  83  94  96 100 103 108 117 120 121 122 126 136 138 139 141 144\n",
            " 148 153 156 157 162 167 172 175 180 182 183 192 202 203 211 214 215 216\n",
            " 217 224 227 231 235 241 248 250 253 255 256 260 261 266 267 270 271 273\n",
            " 275 276 277 280 283 284 288 299 302 304 313 314 315 317 318 322 331 337\n",
            " 340 344 351 354 361 365 366 369 372 375 378 380 392 393 395 400 402 403\n",
            " 408 411 415 424 425 431 433 435 438 440 446 447 453 458 465 468 479 486\n",
            " 487 488 491 497 501 508  10  14  23  36  37  42  48  51  52  53  57  62\n",
            "  64  68  70  79  80  85  87  89  90  97 101 104 106 110 111 113 119 124\n",
            " 132 133 134 142 146 152 155 169 173 177 185 186 189 191 194 196 197 204\n",
            " 206 208 212 219 221 223 226 228 230 233 234 236 237 238 239 245 246 247\n",
            " 254 257 259 262 281 282 285 289 290 292 294 295 306 307 310 311 312 319\n",
            " 321 323 325 327 330 333 335 336 338 341 342 345 347 350 357 368 373 397\n",
            " 399 407 413 414 417 418 427 428 441 443 444 449 450 451 452 455 461 462\n",
            " 467 469 473 480 482 489 490 498 500 502 503 510]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdbxSxj2pa1s",
        "colab_type": "code",
        "outputId": "264f2cda-0bc4-4e89-daa1-614f2db8867a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# SVM com kernel RBF (funciona bem para dados não linearmente separáveis, mas pode aprender demais sobre os dados - overfitting)\n",
        "\n",
        "# Import da função e do pacote metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "# Escolhendo o modelo\n",
        "modelo = SVC(gamma='auto', kernel = 'rbf')\n",
        "\n",
        "# Print dos parâmetros do modelo\n",
        "print(modelo.get_params)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Treinamento e avaliação do modelo\n",
        "treinarAvaliarModelo(modelo)\n",
        "\n",
        "# Imprimindo os vetores de suporte\n",
        "print(\"\\n\")\n",
        "print (modelo.support_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)>\n",
            "\n",
            "\n",
            "=== Usando validação cruzada ===\n",
            "Acurácia de treino: 100.00%\n",
            "Acurácia de teste: 65.11%\n",
            "AUC de treino: 100.00%\n",
            "AUC de teste: 62.98%\n",
            "\n",
            "\n",
            "=== Usando particionamento treino-teste ===\n",
            "Acurácia de teste: 63.78%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      1.00      0.78       162\n",
            "         1.0       0.00      0.00      0.00        92\n",
            "\n",
            "    accuracy                           0.64       254\n",
            "   macro avg       0.32      0.50      0.39       254\n",
            "weighted avg       0.41      0.64      0.50       254\n",
            "\n",
            "[[162   0]\n",
            " [ 92   0]]\n",
            "\n",
            "\n",
            "[  0   1   2   3   4   5   6   7   8   9  12  13  15  16  17  18  19  20\n",
            "  22  24  25  27  29  30  31  32  33  34  35  38  39  40  43  44  45  46\n",
            "  47  49  50  54  55  56  58  59  60  63  65  66  67  69  73  74  75  76\n",
            "  77  78  81  82  83  84  86  88  91  92  93  94  95  96  99 100 102 103\n",
            " 105 108 109 112 114 115 116 117 118 120 121 122 125 126 127 129 130 131\n",
            " 135 136 137 138 139 140 141 143 144 147 148 149 150 151 153 154 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 170 171 172 174 175 176 178 179\n",
            " 180 182 183 184 190 192 193 195 198 199 200 201 202 203 205 209 211 214\n",
            " 215 216 217 220 224 225 227 229 231 232 235 240 241 242 243 244 248 250\n",
            " 251 252 253 255 256 258 260 261 263 264 266 267 268 269 270 271 272 273\n",
            " 274 275 276 277 278 279 280 283 284 286 287 288 291 297 298 299 300 301\n",
            " 302 303 304 305 308 309 313 314 315 317 318 320 322 326 328 329 331 332\n",
            " 334 337 339 340 344 346 348 349 351 352 353 354 355 356 358 359 361 362\n",
            " 363 364 365 366 367 369 370 371 372 374 375 376 377 378 380 381 382 383\n",
            " 384 385 387 388 389 390 391 392 393 394 395 396 398 400 401 402 403 404\n",
            " 405 408 410 411 412 415 416 419 421 422 423 424 425 426 429 430 431 432\n",
            " 433 434 435 436 437 438 439 440 442 445 446 447 448 453 454 457 458 459\n",
            " 463 464 465 468 470 471 474 475 476 477 478 479 481 483 484 486 487 488\n",
            " 491 492 493 495 496 497 499 501 504 506 507 508 511 512  10  11  14  21\n",
            "  23  26  28  36  37  41  42  48  51  52  53  57  61  62  64  68  70  71\n",
            "  72  79  80  85  87  89  90  97  98 101 104 106 107 110 111 113 119 123\n",
            " 124 128 132 133 134 142 145 146 152 155 168 169 173 177 181 185 186 187\n",
            " 188 189 191 194 196 197 204 206 207 208 210 212 213 218 219 221 222 223\n",
            " 226 228 230 233 234 236 237 238 239 245 246 247 249 254 257 259 262 265\n",
            " 281 282 285 289 290 292 293 294 295 296 306 307 310 311 312 316 319 321\n",
            " 323 324 325 327 330 333 335 336 338 341 342 343 345 347 350 357 360 368\n",
            " 373 379 386 397 399 406 407 409 413 414 417 418 420 427 428 441 443 444\n",
            " 449 450 451 452 455 456 460 461 462 466 467 469 472 473 480 482 485 489\n",
            " 490 494 498 500 502 503 505 509 510 513]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNyFsV6h1vjV",
        "colab_type": "text"
      },
      "source": [
        "# Tuning Automático de Hiperparâmetros\n",
        "Podemos avaliar de forma fácil diversas variações de parâmetros de algoritmos usando a função *GridSearchCV*. Para tal, vamos criar uma função de tuning que recebe um modelo, um conjunto de parâmetros, a métrica de avaliação e o número de folds. Esta função irá imprimir o modelo com o melhor resultado.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPTIw-bmjC_l",
        "colab_type": "text"
      },
      "source": [
        "Vamos padronizar os dados e trabalhar com validação cruzada 10-fold. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVlAYayqIx5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import das funções\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Padronização dos dados\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_padronizado = scaler.transform(X)\n",
        "\n",
        "# Definição dos valores para os folds e seed\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "\n",
        "# Separando os dados em folds\n",
        "kfold = KFold(n_splits=num_folds, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R_6JMtVJ4E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningHiperparametros (modelo, param_grid, scoring, kfold):\n",
        "  \n",
        "  # Avaliação de todas as combinações\n",
        "  grid = GridSearchCV(estimator=modelo, param_grid=param_grid, scoring=scoring, cv=kfold,\n",
        "      iid=True)\n",
        "  grid_result = grid.fit(X_padronizado, Y)\n",
        "\n",
        "  # Imprime o modelo com o melhor resultado\n",
        "  print(\"Melhor: %f com %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
        "\n",
        "  # Imprime todos os resultados\n",
        "  means = grid_result.cv_results_['mean_test_score']\n",
        "  stds = grid_result.cv_results_['std_test_score']\n",
        "  params = grid_result.cv_results_['params']\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) com: %r\" % (mean, stdev, param))\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efTsYC_BKYYW",
        "colab_type": "text"
      },
      "source": [
        "Iremos variar os hiperparâmetros dos modelos: Árvore de Decisão, KNN e SVM. No NaiveBayes não há muito que variar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC7QwtAoNjWB",
        "colab_type": "text"
      },
      "source": [
        "## Árvores de Decisão\n",
        "Vamos testar os critérios gini e entropia e variar o tamanho máximo da árvore e o mínimo de exemplos em cada nó folha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLsTjqrXLcDW",
        "colab_type": "code",
        "outputId": "be5ee9ab-759f-4c18-b6bf-b10a0b920288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Definição dos possíveis valores de hiperparâmetros\n",
        "criterios = ['gini', 'entropy']\n",
        "max_depth = [3,5,10,20,30,40,50]\n",
        "min_samples_leaf = [3,5,10,20,30,40,50]\n",
        "param_grid = dict(criterion=criterios, min_samples_leaf=min_samples_leaf, max_depth=max_depth)\n",
        "\n",
        "# Escolha do modelo\n",
        "modelo = DecisionTreeClassifier()\n",
        "\n",
        "# Definição da métrica de avaliação\n",
        "scoring = 'accuracy'\n",
        "#scoring = 'roc_auc'\n",
        "\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "tuningHiperparametros(modelo, param_grid, scoring, kfold)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Melhor: 0.768229 com {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 30}\n",
            "0.744792 (0.067192) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 3}\n",
            "0.744792 (0.067192) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 5}\n",
            "0.747396 (0.065277) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 10}\n",
            "0.750000 (0.063736) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 20}\n",
            "0.751302 (0.061211) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 30}\n",
            "0.753906 (0.064729) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 40}\n",
            "0.755208 (0.063515) com: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 50}\n",
            "0.742188 (0.073153) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 3}\n",
            "0.744792 (0.081988) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5}\n",
            "0.757812 (0.081377) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10}\n",
            "0.755208 (0.090481) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 20}\n",
            "0.768229 (0.068368) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 30}\n",
            "0.752604 (0.076233) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 40}\n",
            "0.730469 (0.069908) com: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 50}\n",
            "0.712240 (0.056492) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 3}\n",
            "0.718750 (0.065971) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 5}\n",
            "0.738281 (0.060961) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 10}\n",
            "0.763021 (0.091074) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 20}\n",
            "0.747396 (0.072964) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 30}\n",
            "0.752604 (0.076233) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 40}\n",
            "0.730469 (0.069908) com: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 50}\n",
            "0.707031 (0.049195) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 3}\n",
            "0.718750 (0.058333) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 5}\n",
            "0.740885 (0.060346) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 10}\n",
            "0.763021 (0.091074) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 20}\n",
            "0.747396 (0.072964) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 30}\n",
            "0.752604 (0.076233) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 40}\n",
            "0.730469 (0.069908) com: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 50}\n",
            "0.696615 (0.056246) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 3}\n",
            "0.713542 (0.064518) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 5}\n",
            "0.734375 (0.065401) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 10}\n",
            "0.761719 (0.094034) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 20}\n",
            "0.747396 (0.072964) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 30}\n",
            "0.752604 (0.076233) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 40}\n",
            "0.730469 (0.069908) com: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 50}\n",
            "0.701823 (0.056562) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 3}\n",
            "0.707031 (0.061643) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 5}\n",
            "0.736979 (0.059837) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 10}\n",
            "0.761719 (0.094034) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 20}\n",
            "0.747396 (0.072964) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 30}\n",
            "0.752604 (0.076233) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 40}\n",
            "0.730469 (0.069908) com: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 50}\n",
            "0.696615 (0.056045) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 3}\n",
            "0.710938 (0.064778) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 5}\n",
            "0.736979 (0.066097) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 10}\n",
            "0.761719 (0.094034) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 20}\n",
            "0.747396 (0.072964) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 30}\n",
            "0.752604 (0.076233) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 40}\n",
            "0.730469 (0.069908) com: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 50}\n",
            "0.748698 (0.061137) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 3}\n",
            "0.748698 (0.061137) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 5}\n",
            "0.748698 (0.061137) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 10}\n",
            "0.748698 (0.061137) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 20}\n",
            "0.748698 (0.061137) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 30}\n",
            "0.748698 (0.060859) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 40}\n",
            "0.750000 (0.059681) com: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 50}\n",
            "0.739583 (0.069148) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 3}\n",
            "0.734375 (0.068331) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5}\n",
            "0.752604 (0.081585) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10}\n",
            "0.751302 (0.071098) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 20}\n",
            "0.757812 (0.076039) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 30}\n",
            "0.757812 (0.080153) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 40}\n",
            "0.738281 (0.072043) com: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 50}\n",
            "0.707031 (0.069044) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 3}\n",
            "0.696615 (0.057927) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 5}\n",
            "0.730469 (0.069063) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 10}\n",
            "0.753906 (0.078095) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 20}\n",
            "0.739583 (0.072380) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 30}\n",
            "0.751302 (0.083865) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 40}\n",
            "0.738281 (0.072043) com: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 50}\n",
            "0.717448 (0.051287) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 3}\n",
            "0.696615 (0.060123) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 5}\n",
            "0.726562 (0.070111) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 10}\n",
            "0.753906 (0.078095) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 20}\n",
            "0.739583 (0.072380) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 30}\n",
            "0.751302 (0.083865) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 40}\n",
            "0.738281 (0.072043) com: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 50}\n",
            "0.709635 (0.065857) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 3}\n",
            "0.694010 (0.062544) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 5}\n",
            "0.729167 (0.070444) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 10}\n",
            "0.753906 (0.078095) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 20}\n",
            "0.739583 (0.072380) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 30}\n",
            "0.751302 (0.083865) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 40}\n",
            "0.738281 (0.072043) com: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 50}\n",
            "0.703125 (0.072988) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 3}\n",
            "0.695312 (0.059214) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 5}\n",
            "0.726562 (0.071655) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 10}\n",
            "0.753906 (0.078095) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 20}\n",
            "0.739583 (0.072380) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 30}\n",
            "0.751302 (0.083865) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 40}\n",
            "0.738281 (0.072043) com: {'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 50}\n",
            "0.723958 (0.074727) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 3}\n",
            "0.697917 (0.051914) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 5}\n",
            "0.727865 (0.069378) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 10}\n",
            "0.753906 (0.078095) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 20}\n",
            "0.739583 (0.072380) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 30}\n",
            "0.751302 (0.083865) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 40}\n",
            "0.738281 (0.072043) com: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkcXNl1M1pas",
        "colab_type": "text"
      },
      "source": [
        "## KNN\n",
        "O número padrão de vizinhos (k) para o KNN é 5. Vamos testar todos os valores ímpares entre 1 a 21 para k, cobrindo o valor padrão de 5 e 3 diferentes medidas de distância."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHj02w511pqm",
        "colab_type": "code",
        "outputId": "0ff91705-e8de-4dd4-9733-65996a08570f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# Definição dos possíveis valores de hiperparâmetros\n",
        "k = [1,3,5,7,9,11,13,15,17,19,21]\n",
        "distancias = [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
        "param_grid = dict(n_neighbors=k, metric=distancias)\n",
        "\n",
        "# Escolha do modelo\n",
        "modelo = KNeighborsClassifier()\n",
        "\n",
        "# Definição da métrica de avaliação\n",
        "scoring = 'accuracy'\n",
        "#scoring = 'roc_auc'\n",
        "\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "tuningHiperparametros(modelo, param_grid, scoring, kfold)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Melhor: 0.761719 com {'metric': 'euclidean', 'n_neighbors': 21}\n",
            "0.708333 (0.054371) com: {'metric': 'euclidean', 'n_neighbors': 1}\n",
            "0.746094 (0.066029) com: {'metric': 'euclidean', 'n_neighbors': 3}\n",
            "0.742188 (0.071583) com: {'metric': 'euclidean', 'n_neighbors': 5}\n",
            "0.742188 (0.068443) com: {'metric': 'euclidean', 'n_neighbors': 7}\n",
            "0.743490 (0.071178) com: {'metric': 'euclidean', 'n_neighbors': 9}\n",
            "0.747396 (0.053738) com: {'metric': 'euclidean', 'n_neighbors': 11}\n",
            "0.746094 (0.048545) com: {'metric': 'euclidean', 'n_neighbors': 13}\n",
            "0.739583 (0.054897) com: {'metric': 'euclidean', 'n_neighbors': 15}\n",
            "0.743490 (0.062820) com: {'metric': 'euclidean', 'n_neighbors': 17}\n",
            "0.760417 (0.064617) com: {'metric': 'euclidean', 'n_neighbors': 19}\n",
            "0.761719 (0.074144) com: {'metric': 'euclidean', 'n_neighbors': 21}\n",
            "0.694010 (0.042855) com: {'metric': 'manhattan', 'n_neighbors': 1}\n",
            "0.721354 (0.069181) com: {'metric': 'manhattan', 'n_neighbors': 3}\n",
            "0.733073 (0.065550) com: {'metric': 'manhattan', 'n_neighbors': 5}\n",
            "0.739583 (0.072673) com: {'metric': 'manhattan', 'n_neighbors': 7}\n",
            "0.756510 (0.051447) com: {'metric': 'manhattan', 'n_neighbors': 9}\n",
            "0.750000 (0.059339) com: {'metric': 'manhattan', 'n_neighbors': 11}\n",
            "0.751302 (0.053424) com: {'metric': 'manhattan', 'n_neighbors': 13}\n",
            "0.751302 (0.061147) com: {'metric': 'manhattan', 'n_neighbors': 15}\n",
            "0.751302 (0.058672) com: {'metric': 'manhattan', 'n_neighbors': 17}\n",
            "0.752604 (0.057770) com: {'metric': 'manhattan', 'n_neighbors': 19}\n",
            "0.757812 (0.063614) com: {'metric': 'manhattan', 'n_neighbors': 21}\n",
            "0.708333 (0.054371) com: {'metric': 'minkowski', 'n_neighbors': 1}\n",
            "0.746094 (0.066029) com: {'metric': 'minkowski', 'n_neighbors': 3}\n",
            "0.742188 (0.071583) com: {'metric': 'minkowski', 'n_neighbors': 5}\n",
            "0.742188 (0.068443) com: {'metric': 'minkowski', 'n_neighbors': 7}\n",
            "0.743490 (0.071178) com: {'metric': 'minkowski', 'n_neighbors': 9}\n",
            "0.747396 (0.053738) com: {'metric': 'minkowski', 'n_neighbors': 11}\n",
            "0.746094 (0.048545) com: {'metric': 'minkowski', 'n_neighbors': 13}\n",
            "0.739583 (0.054897) com: {'metric': 'minkowski', 'n_neighbors': 15}\n",
            "0.743490 (0.062820) com: {'metric': 'minkowski', 'n_neighbors': 17}\n",
            "0.760417 (0.064617) com: {'metric': 'minkowski', 'n_neighbors': 19}\n",
            "0.761719 (0.074144) com: {'metric': 'minkowski', 'n_neighbors': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya1f4vEd2OoU",
        "colab_type": "text"
      },
      "source": [
        "## SVM\n",
        "Podemos ajustar dois parâmetros principais do algoritmo SVM, o valor de C (o quanto flexibilizar a margem) e o tipo de kernel. O padrão para o SVM (classe SVC) é usar o kernel da Função Base Base Radial (RBF) com um valor C definido como 1.0. Vamos testar vários tipos de kernel e valores C com menos viés e mais viés (menor que e maior que 1,0, respectivamente)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VZmpIPu2Ow3",
        "colab_type": "code",
        "outputId": "0f2595cb-ea48-4cda-a991-4942634e4c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Definição dos possíveis valores de hiperparâmetros\n",
        "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "param_grid = dict(C=c_values, kernel=kernel_values)\n",
        "\n",
        "# Escolha do modelo\n",
        "modelo = SVC(gamma='auto')\n",
        "\n",
        "# Definição da métrica de avaliação\n",
        "scoring = 'accuracy'\n",
        "#scoring = 'roc_auc'\n",
        "\n",
        "# Avaliação de todas as combinações e impressão dos resultados\n",
        "tuningHiperparametros(modelo, param_grid, scoring, kfold)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Melhor: 0.774740 com {'C': 1.5, 'kernel': 'linear'}\n",
            "0.773438 (0.048948) com: {'C': 0.1, 'kernel': 'linear'}\n",
            "0.718750 (0.052248) com: {'C': 0.1, 'kernel': 'poly'}\n",
            "0.755208 (0.053681) com: {'C': 0.1, 'kernel': 'rbf'}\n",
            "0.755208 (0.056916) com: {'C': 0.1, 'kernel': 'sigmoid'}\n",
            "0.772135 (0.045249) com: {'C': 0.3, 'kernel': 'linear'}\n",
            "0.733073 (0.051177) com: {'C': 0.3, 'kernel': 'poly'}\n",
            "0.772135 (0.061996) com: {'C': 0.3, 'kernel': 'rbf'}\n",
            "0.730469 (0.044574) com: {'C': 0.3, 'kernel': 'sigmoid'}\n",
            "0.770833 (0.047759) com: {'C': 0.5, 'kernel': 'linear'}\n",
            "0.735677 (0.049609) com: {'C': 0.5, 'kernel': 'poly'}\n",
            "0.769531 (0.059389) com: {'C': 0.5, 'kernel': 'rbf'}\n",
            "0.718750 (0.045850) com: {'C': 0.5, 'kernel': 'sigmoid'}\n",
            "0.773438 (0.045619) com: {'C': 0.7, 'kernel': 'linear'}\n",
            "0.740885 (0.045356) com: {'C': 0.7, 'kernel': 'poly'}\n",
            "0.769531 (0.059673) com: {'C': 0.7, 'kernel': 'rbf'}\n",
            "0.712240 (0.049995) com: {'C': 0.7, 'kernel': 'sigmoid'}\n",
            "0.773438 (0.045619) com: {'C': 0.9, 'kernel': 'linear'}\n",
            "0.740885 (0.042559) com: {'C': 0.9, 'kernel': 'poly'}\n",
            "0.765625 (0.053821) com: {'C': 0.9, 'kernel': 'rbf'}\n",
            "0.710938 (0.050616) com: {'C': 0.9, 'kernel': 'sigmoid'}\n",
            "0.773438 (0.045619) com: {'C': 1.0, 'kernel': 'linear'}\n",
            "0.746094 (0.042059) com: {'C': 1.0, 'kernel': 'poly'}\n",
            "0.764323 (0.056996) com: {'C': 1.0, 'kernel': 'rbf'}\n",
            "0.703125 (0.043175) com: {'C': 1.0, 'kernel': 'sigmoid'}\n",
            "0.773438 (0.045619) com: {'C': 1.3, 'kernel': 'linear'}\n",
            "0.752604 (0.043930) com: {'C': 1.3, 'kernel': 'poly'}\n",
            "0.764323 (0.054387) com: {'C': 1.3, 'kernel': 'rbf'}\n",
            "0.708333 (0.043706) com: {'C': 1.3, 'kernel': 'sigmoid'}\n",
            "0.774740 (0.045870) com: {'C': 1.5, 'kernel': 'linear'}\n",
            "0.752604 (0.041042) com: {'C': 1.5, 'kernel': 'poly'}\n",
            "0.761719 (0.052329) com: {'C': 1.5, 'kernel': 'rbf'}\n",
            "0.694010 (0.048211) com: {'C': 1.5, 'kernel': 'sigmoid'}\n",
            "0.774740 (0.045870) com: {'C': 1.7, 'kernel': 'linear'}\n",
            "0.753906 (0.044117) com: {'C': 1.7, 'kernel': 'poly'}\n",
            "0.768229 (0.051929) com: {'C': 1.7, 'kernel': 'rbf'}\n",
            "0.697917 (0.045333) com: {'C': 1.7, 'kernel': 'sigmoid'}\n",
            "0.774740 (0.045870) com: {'C': 2.0, 'kernel': 'linear'}\n",
            "0.753906 (0.044499) com: {'C': 2.0, 'kernel': 'poly'}\n",
            "0.769531 (0.052025) com: {'C': 2.0, 'kernel': 'rbf'}\n",
            "0.701823 (0.043630) com: {'C': 2.0, 'kernel': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm1x2PSMT4Q9",
        "colab_type": "text"
      },
      "source": [
        "# Comparação gráfica de algoritmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPNwZ_uXRiyl",
        "colab_type": "text"
      },
      "source": [
        "Quando trabalhamos em projetos de Machine Learning, geralmente temos vários bons modelos para escolher. Cada modelo terá características de desempenho diferentes. É importante usar várias métricas diferentes para avaliar os algoritmos.\n",
        "\n",
        "Para que seja feita uma comparação justa, é preciso garantir que cada algoritmo seja avaliado da mesma maneira nos mesmos dados. É importante usar a mesma semente aleatória para garantir que as mesmas divisões nos dados de treinamento sejam executadas e que cada algoritmo seja avaliado precisamente da mesma maneira.\n",
        "\n",
        "Neste exemplo, iremos avaliar diversos modelos usando uma representação gráfica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtmuzqWURyGw",
        "colab_type": "code",
        "outputId": "c69d8986-59ac-463f-fb96-1fbc7908f42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "# Comparação de Algortimos\n",
        "\n",
        "# Import da função\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Lista de modelos a avaliar\n",
        "modelos = []\n",
        "# Aqui, poderíamos criar o modelo já parametrizado com os melhores hiperparâmetros da seção anterior\n",
        "modelos.append(('CART', DecisionTreeClassifier()))\n",
        "modelos.append(('KNN', KNeighborsClassifier()))\n",
        "modelos.append(('NB', GaussianNB()))\n",
        "modelos.append(('SVM', SVC(gamma='auto')))\n",
        "\n",
        "# Treinamento e avaliação de cada modelo\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in modelos:\n",
        "  kfold = KFold(n_splits=10, random_state=7)\n",
        "  cv_results = cross_val_score(model, X_padronizado, Y, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)\n",
        "  \n",
        "# Comparação dos algoritmos em boxplot\n",
        "fig = pyplot.figure() \n",
        "fig.suptitle('Comparação dos algoritmos') \n",
        "ax = fig.add_subplot(111) \n",
        "pyplot.boxplot(results) \n",
        "ax.set_xticklabels(names) \n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CART: 0.688773 (0.069996)\n",
            "KNN: 0.742139 (0.071500)\n",
            "NB: 0.755178 (0.042766)\n",
            "SVM: 0.764286 (0.056962)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/DulN1NdHPY3VgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}